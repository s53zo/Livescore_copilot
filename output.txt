===== README.md =====
# Livescore Pilot - Live Contest Scoring Application

## Project Overview

**Livescore Pilot** is a web application designed to facilitate real-time contest scoring for amateur radio contests. It enables participants to monitor their performance, compare scores with nearby competitors, and apply filters based on geographical or operational criteria. The application comprises server-side scripts for data ingestion and processing, a SQLite database for storing contest data, and a web interface for user interaction.

## Key Features

- **Real-Time Scoring**: Provides up-to-date contest scores and standings for participants.
- **Filtering Options**: Allows users to filter competitors by DXCC country, CQ zone, or IARU zone.
- **Band Breakdown**: Offers a detailed view of QSOs, points, and multipliers for each band.
- **QSO Rate Calculation**: Displays the rate of QSOs over a specified time interval to help users assess their performance trends.
- **Automatic Refresh**: The report page refreshes automatically to display the latest data.
- **User-Friendly Interface**: Provides an intuitive web interface for selecting contests, callsigns, and applying filters.

## Architecture

### 1. Data Ingestion

- **XML Data Reception**: The `livescore.py` script runs an HTTP server that listens for POST requests containing XML-formatted contest data.
- **XML Parsing and Validation**: Parses the received XML data, extracts contest information, and validates the data format.
- **Data Storage**: Stores the parsed data in a SQLite database (`contest_data.db`), including contest scores and band breakdowns.

### 2. Database Management

- **Index Creation**: The `database_manager.py` script can create indexes to optimize database queries.
- **Cleanup Operations**: Removes contests with fewer participants than a specified threshold to maintain database efficiency.
- **Reindexing**: Provides functionality to rebuild indexes for performance optimization.

### 3. Data Analysis and Reporting

- **Score Retrieval**: The `ContestDatabaseViewer` class in `contest_db_viewer.py` retrieves scores, band breakdowns, and statistics from the database.
- **Report Generation**: `ScoreReporter` in `score_reporter.py` generates HTML reports using data from the database and HTML templates.
- **Rate Calculations**: Calculates QSO rates over a specified interval to provide insights into performance trends.

### 4. Web Interface

- **User Interaction**: The Flask app (`web_interface.py`) allows users to select contests and callsigns, and apply filters.
- **Live Reports**: Generates and serves live contest progress reports, updating at regular intervals.
- **Error Handling**: Provides user-friendly error messages via the `error.html` template.

### 5. Service Deployment

- **Systemd Service**: The `livescore-pilot.service` file allows the application to run as a service managed by systemd.
- **Gunicorn Configuration**: `gunicorn_config.py` specifies how Gunicorn should run the Flask app, including worker settings and logging.

## Installation

### Prerequisites

- Python 3.6 or higher
- SQLite3
- Flask
- Gunicorn

### Steps

1. **Clone the Repository**

   ```bash
   git clone https://github.com/yourusername/livescore-pilot.git
   cd livescore-pilot
   ```

2. **Install Dependencies**

  Python will tell you about missing dependencies.

3. **Set Up the Database**

   The database will be automatically created when the application runs for the first time.

4. **Configure the Application**

   - Update `gunicorn_config.py` and `livescore-pilot.service` files with appropriate paths and settings.
   - Ensure that the `Config` class in `web_interface.py` points to the correct database and output directories.

5. **Run the Application**

   - For development:

     ```bash
     python web_interface.py
     ```

   - For production using Gunicorn and systemd:

     - Copy `livescore-pilot.service` to `/etc/systemd/system/`
     - Reload systemd and start the service:

       ```bash
       sudo systemctl daemon-reload
       sudo systemctl start livescore-pilot.service
       sudo systemctl enable livescore-pilot.service
       ```

## Usage

1. **Data Submission**

   - Contest participants configure their logging software to submit data to livescore servers.

2. **Accessing the Web Interface**

   - Navigate to `https://azure.s53m.com/livescore-pilot` to access the user interface.
   - Select the contest and callsign, and apply any desired filters.

3. **Viewing Live Reports**

   - After submitting the form, the application generates a live report displaying the contest progress.
   - The report automatically refreshes at set intervals to provide real-time updates.

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request for review.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Developed by Simon, S53ZO.
- Data sourced from competitors via the Contest Score Distribution Network.

===== batch_processor.py =====
#!/usr/bin/env python3
import queue
import threading
import time
import logging
from datetime import datetime

class BatchProcessor:
    def __init__(self, db_handler, batch_interval=60):
        self.db_handler = db_handler
        self.batch_interval = batch_interval
        self.queue = queue.Queue()
        self.is_running = False
        self.processing_thread = None
        self.batch_size = 0
        self.logger = logging.getLogger('BatchProcessor')
        
    def start(self):
        """Start the batch processing thread"""
        if not self.is_running:
            self.is_running = True
            self.processing_thread = threading.Thread(target=self._process_batch_loop)
            self.processing_thread.daemon = True
            self.processing_thread.start()
            self.logger.info("Batch processor started")
    
    def stop(self):
        """Stop the batch processing thread"""
        self.is_running = False
        if self.processing_thread:
            self.processing_thread.join()
            self.logger.info("Batch processor stopped")
    
    def add_to_batch(self, xml_data):
        """Add XML data to processing queue"""
        self.queue.put(xml_data)
        self.batch_size += 1
        self.logger.debug(f"Added to batch. Current size: {self.batch_size}")

    # In batch_processor.py, add:
    def pause_processing(self):
        """Pause batch processing temporarily"""
        self.paused = True
        
    def resume_processing(self):
        """Resume batch processing"""
        self.paused = False
    
    def _process_batch_loop(self):
        """Main processing loop - runs every batch_interval seconds"""
        while self.is_running:
            start_time = time.time()
            batch = []
            
            try:
                while True:
                    batch.append(self.queue.get_nowait())
                    self.batch_size -= 1
            except queue.Empty:
                pass
            
            if batch:
                try:
                    batch_start = time.time()
                    self.logger.info(f"Processing batch of {len(batch)} items")
                    
                    combined_xml = "\n".join(batch)
                    contest_data = self.db_handler.parse_xml_data(combined_xml)
                    if contest_data:
                        self.db_handler.store_data(contest_data)
                    
                    batch_time = time.time() - batch_start
                    self.logger.info(f"Batch processed in {batch_time:.2f} seconds")
                    
                except Exception as e:
                    self.logger.error(f"Error processing batch: {e}")
            
            elapsed = time.time() - start_time
            sleep_time = max(0, self.batch_interval - elapsed)
            time.sleep(sleep_time)

===== callsign_utils.py =====
#!/usr/bin/env python3
import plistlib
import logging
from typing import Dict, Optional

class CallsignLookup:
    def __init__(self, plist_path: str = "cty.plist"):
        self.cty_list = self._load_plist(plist_path)
        self._cache: Dict[str, dict] = {}
        
    def get_callsign_info(self, callsign: str) -> Optional[dict]:
        """Get callsign info, always using the Prefix field from CTY.plist entry"""
        if callsign in self._cache:
            return self._cache[callsign]
        
        base_call = callsign.split('/')[0]
        info = None
        
        # First check for exact callsign match
        if base_call in self.cty_list:
            info = self.cty_list[base_call]
        else:
            # Then check for prefix match
            for i in range(len(base_call), 0, -1):
                prefix = base_call[:i]
                if prefix in self.cty_list:
                    info = self.cty_list[prefix]
                    break
        
        if info:
            result = {
                "prefix": info.get("Prefix", ""),  # Use the Prefix field from CTY.plist
                "country": info.get("Country", ""),
                "continent": info.get("Continent", ""),
                "adif": info.get("ADIF", 0),
                "cq_zone": info.get("CQZone", 0),
                "itu_zone": info.get("ITUZone", 0),
                "latitude": info.get("Latitude", 0.0),
                "longitude": info.get("Longitude", 0.0)
            }
            self._cache[callsign] = result
            return result
        
        self._cache[callsign] = None
        return None

    def clear_cache(self) -> None:
        self._cache.clear()

    def _load_plist(self, plist_path: str) -> dict:
        try:
            with open(plist_path, 'rb') as file:
                return plistlib.load(file)
        except FileNotFoundError:
            logging.error(f"Error: {plist_path} not found")
            raise
        except Exception as e:
            logging.error(f"Error loading {plist_path}: {e}")
            raise
    
    def get_country(self, callsign: str) -> Optional[str]:
        info = self.get_callsign_info(callsign)
        return info["country"] if info else None
        
    def get_continent(self, callsign: str) -> Optional[str]:
        info = self.get_callsign_info(callsign)
        return info["continent"] if info else None

===== cat.sh =====
for file in *; do
    # Skip directories to avoid errors
    if [ -f "$file" ]; then
      echo "===== $file =====" >> output.txt
      cat "$file" >> output.txt
      echo "" >> output.txt   # Add a blank line
    fi
done

===== cleanup_scores.py =====
#!/usr/bin/env python3

import sqlite3
import argparse
from datetime import datetime, timedelta


def cleanup_scores(db_path, dry_run, callsign=None, contest=None, minutes=90):
    """
    Retains only the latest `minutes` of scores for specified callsign and contest.

    :param db_path: Path to the SQLite database.
    :param dry_run: If True, no changes are made to the database; just prints the deletions.
    :param callsign: Filter by callsign (optional).
    :param contest: Filter by contest (optional).
    :param minutes: Time period (in minutes) to retain scores.
    """
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()

            # Build query to fetch latest timestamps
            query = """
                SELECT callsign, contest, MAX(timestamp) AS latest_timestamp
                FROM contest_scores
                WHERE 1=1
            """
            params = []

            # Apply filters
            if callsign:
                query += " AND callsign = ?"
                params.append(callsign)
            if contest:
                query += " AND contest = ?"
                params.append(contest)

            query += " GROUP BY callsign, contest"
            cursor.execute(query, params)
            latest_entries = cursor.fetchall()

            print(f"Found {len(latest_entries)} callsign-contest combinations to process.\n")

            total_deleted = 0
            for entry_callsign, entry_contest, latest_timestamp in latest_entries:
                latest_time = datetime.strptime(latest_timestamp, '%Y-%m-%d %H:%M:%S')
                cutoff_time = latest_time - timedelta(minutes=minutes)

                # Find entries older than the cutoff
                cursor.execute("""
                    SELECT id, timestamp FROM contest_scores
                    WHERE callsign = ? AND contest = ? AND timestamp < ?
                """, (entry_callsign, entry_contest, cutoff_time.strftime('%Y-%m-%d %H:%M:%S')))
                old_entries = cursor.fetchall()

                if old_entries:
                    print(f"Callsign: {entry_callsign}, Contest: {entry_contest}")
                    print(f"  Latest entry: {latest_time}")
                    print(f"  Retaining scores from the last {minutes} minutes.")
                    print(f"  Removing entries older than: {cutoff_time}")
                    print(f"  Entries to delete: {len(old_entries)}")
                    if dry_run:
                        for entry in old_entries:
                            print(f"    Would delete: ID={entry[0]}, Timestamp={entry[1]}")
                    else:
                        # Delete the old entries
                        cursor.executemany("""
                            DELETE FROM contest_scores WHERE id = ?
                        """, [(entry[0],) for entry in old_entries])
                        print(f"  Deleted {len(old_entries)} entries.")

                    total_deleted += len(old_entries)

            if not dry_run:
                conn.commit()
                print(f"\nCleanup complete. Total entries deleted: {total_deleted}")
            else:
                print(f"\nDry-run complete. Total entries that would be deleted: {total_deleted}")

    except sqlite3.Error as e:
        print(f"Database error: {e}")
    except Exception as e:
        print(f"Error: {e}")


def main():
    parser = argparse.ArgumentParser(
        description="Clean up old scores from contest database."
    )
    parser.add_argument("--db", required=True, help="Path to the SQLite database file.")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview the changes without making any deletions.",
    )
    parser.add_argument(
        "--callsign",
        help="Filter by callsign (optional). Only process scores for this callsign.",
    )
    parser.add_argument(
        "--contest",
        help="Filter by contest (optional). Only process scores for this contest.",
    )
    parser.add_argument(
        "--minutes",
        type=int,
        default=90,
        help="Time period (in minutes) to retain scores. Default: 90 minutes.",
    )

    args = parser.parse_args()

    print(f"Starting cleanup process on database: {args.db}")
    print(f"Dry-run mode: {'ON' if args.dry_run else 'OFF'}")
    if args.callsign:
        print(f"Filter: Callsign = {args.callsign}")
    if args.contest:
        print(f"Filter: Contest = {args.contest}")
    print(f"Time period to retain: {args.minutes} minutes\n")

    cleanup_scores(args.db, args.dry_run, args.callsign, args.contest, args.minutes)


if __name__ == "__main__":
    main()

===== contest_db_viewer.py =====
#!/usr/bin/env python3
import sqlite3
import logging
import sys
from datetime import datetime
from tabulate import tabulate
from display_utils import format_band_stats, format_scores, format_band_breakdown

class ContestDatabaseViewer:
    def __init__(self, db_path, debug=False):
        self.db_path = db_path
        self.debug = debug
        self.setup_logging()
        
    def setup_logging(self):
        """Setup logging configuration """
        log_level = logging.DEBUG if self.debug else logging.INFO
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        self.logger = logging.getLogger('ContestDBViewer')
        self.logger.setLevel(log_level)
        self.logger.addHandler(console_handler)

    def connect_db(self):
        """Connect to the database"""
        try:
            self.logger.debug(f"Connecting to database: {self.db_path}")
            return sqlite3.connect(self.db_path)
        except sqlite3.Error as e:
            self.logger.error(f"Error connecting to database: {e}")
            sys.exit(1)

    def check_callsign_exists(self, callsign):
        """Check if callsign exists in database"""
        query = "SELECT COUNT(*) FROM contest_scores WHERE callsign = ?"
        
        self.logger.debug(f"Checking if callsign exists: {callsign}")
        
        with self.connect_db() as conn:
            cursor = conn.cursor()
            cursor.execute(query, (callsign,))
            count = cursor.fetchone()[0]
            
            if count == 0:
                cursor.execute("SELECT DISTINCT callsign FROM contest_scores ORDER BY callsign")
                available_calls = [row[0] for row in cursor.fetchall()]
                
                print(f"No records found for callsign: {callsign}")
                print("\nAvailable callsigns in database:")
                col_width = max(len(call) for call in available_calls) + 2
                cols = max(1, 80 // col_width)
                for i in range(0, len(available_calls), cols):
                    print("".join(call.ljust(col_width) for call in available_calls[i:i+cols]))
                return False
            return True

    def get_available_contests(self):
        """Get list of all contests in database"""
        query = """
            SELECT DISTINCT contest 
            FROM contest_scores 
            ORDER BY contest
        """
        with self.connect_db() as conn:
            cursor = conn.cursor()
            cursor.execute(query)
            return [row[0] for row in cursor.fetchall()]

    def get_contest_stats(self):
        """Get various statistics from the database"""
        stats_queries = {
            "total_stats": """
                WITH latest_scores AS (
                    SELECT cs.id, cs.callsign, cs.contest, cs.qsos
                    FROM contest_scores cs
                    INNER JOIN (
                        SELECT callsign, contest, MAX(timestamp) as max_ts
                        FROM contest_scores
                        GROUP BY callsign, contest
                    ) latest ON cs.callsign = latest.callsign 
                        AND cs.contest = latest.contest
                        AND cs.timestamp = latest.max_ts
                )
                SELECT 
                    COUNT(DISTINCT callsign) as unique_stations,
                    COUNT(DISTINCT contest) as contests,
                    (SELECT COUNT(*) FROM contest_scores) as total_uploads,
                    SUM(qsos) as total_qsos
                FROM latest_scores
            """,
            "contest_counts": """
                WITH latest_scores AS (
                    SELECT cs.id, cs.callsign, cs.contest, cs.score, cs.qsos, cs.timestamp
                    FROM contest_scores cs
                    INNER JOIN (
                        SELECT callsign, contest, MAX(timestamp) as max_ts
                        FROM contest_scores
                        GROUP BY callsign, contest
                    ) latest ON cs.callsign = latest.callsign 
                        AND cs.contest = latest.contest
                        AND cs.timestamp = latest.max_ts
                )
                SELECT 
                    contest,
                    COUNT(DISTINCT callsign) as participants,
                    COUNT(*) as total_uploads,
                    MIN(timestamp) as first_upload,
                    MAX(timestamp) as last_upload,
                    MAX(score) as highest_score,
                    SUM(qsos) as total_qsos
                FROM latest_scores
                GROUP BY contest
                ORDER BY last_upload DESC
            """,
            "band_stats": """
                WITH latest_scores AS (
                    SELECT cs.id, cs.callsign, cs.contest
                    FROM contest_scores cs
                    INNER JOIN (
                        SELECT callsign, contest, MAX(timestamp) as max_ts
                        FROM contest_scores
                        GROUP BY callsign, contest
                    ) latest ON cs.callsign = latest.callsign 
                        AND cs.contest = latest.contest
                        AND cs.timestamp = latest.max_ts
                )
                SELECT 
                    cs.contest,
                    COUNT(DISTINCT cs.callsign) as stations,
                    SUM(CASE WHEN bb.band = '160' THEN bb.qsos ELSE 0 END) as '160_qsos',
                    SUM(CASE WHEN bb.band = '160' THEN bb.points ELSE 0 END) as '160_points',
                    SUM(CASE WHEN bb.band = '160' THEN bb.multipliers ELSE 0 END) as '160_mults',
                    SUM(CASE WHEN bb.band = '80' THEN bb.qsos ELSE 0 END) as '80_qsos',
                    SUM(CASE WHEN bb.band = '80' THEN bb.points ELSE 0 END) as '80_points',
                    SUM(CASE WHEN bb.band = '80' THEN bb.multipliers ELSE 0 END) as '80_mults',
                    SUM(CASE WHEN bb.band = '40' THEN bb.qsos ELSE 0 END) as '40_qsos',
                    SUM(CASE WHEN bb.band = '40' THEN bb.points ELSE 0 END) as '40_points',
                    SUM(CASE WHEN bb.band = '40' THEN bb.multipliers ELSE 0 END) as '40_mults',
                    SUM(CASE WHEN bb.band = '20' THEN bb.qsos ELSE 0 END) as '20_qsos',
                    SUM(CASE WHEN bb.band = '20' THEN bb.points ELSE 0 END) as '20_points',
                    SUM(CASE WHEN bb.band = '20' THEN bb.multipliers ELSE 0 END) as '20_mults',
                    SUM(CASE WHEN bb.band = '15' THEN bb.qsos ELSE 0 END) as '15_qsos',
                    SUM(CASE WHEN bb.band = '15' THEN bb.points ELSE 0 END) as '15_points',
                    SUM(CASE WHEN bb.band = '15' THEN bb.multipliers ELSE 0 END) as '15_mults',
                    SUM(CASE WHEN bb.band = '10' THEN bb.qsos ELSE 0 END) as '10_qsos',
                    SUM(CASE WHEN bb.band = '10' THEN bb.points ELSE 0 END) as '10_points',
                    SUM(CASE WHEN bb.band = '10' THEN bb.multipliers ELSE 0 END) as '10_mults'
                FROM latest_scores ls
                JOIN contest_scores cs ON cs.id = ls.id
                LEFT JOIN band_breakdown bb ON bb.contest_score_id = cs.id
                GROUP BY cs.contest
                ORDER BY cs.contest
            """
        }

        stats = {}
        with self.connect_db() as conn:
            cursor = conn.cursor()
            for stat_name, query in stats_queries.items():
                cursor.execute(query)
                if stat_name == "total_stats":
                    stats[stat_name] = cursor.fetchone()
                else:
                    stats[stat_name] = cursor.fetchall()
        return stats

    def get_contest_scores(self, sort_by='t', sort_order='DESC', limit=None, latest=False, contest=None):
        """Retrieve contest scores from database"""
        valid_sort_fields = {
            't': 'timestamp',
            'c': 'callsign',
            'n': 'contest',
            's': 'score',
            'q': 'qsos',
            'u': 'club',
            'e': 'section',
            'p': 'power'
        }

        if sort_by not in valid_sort_fields:
            self.logger.error(f"Invalid sort field: {sort_by}")
            self.logger.info(f"Valid sort fields are: {', '.join(valid_sort_fields.keys())}")
            sys.exit(1)

        sort_order = sort_order.upper()
        if sort_order not in ['ASC', 'DESC']:
            self.logger.error(f"Invalid sort order: {sort_order}")
            self.logger.info("Valid sort orders are: ASC, DESC")
            sys.exit(1)

        # Use a subquery to get the latest record ID for each callsign/contest combination
        query = """
            WITH latest_records AS (
                SELECT MAX(id) as latest_id
                FROM contest_scores cs1
                WHERE 1=1
                {contest_filter}
                GROUP BY callsign, contest
            )
            SELECT 
                cs.timestamp,
                cs.contest,
                cs.callsign,
                cs.power,
                cs.score,
                cs.qsos,
                cs.multipliers,
                cs.club,
                cs.section,
                cs.assisted,
                cs.mode
            FROM contest_scores cs
            INNER JOIN latest_records lr ON cs.id = lr.latest_id
            ORDER BY {sort_field} {sort_order}
            {limit_clause}
        """

        contest_where = ""
        params = []
        if contest:
            contest_where = "AND contest = ?"
            params.append(contest)

        formatted_query = query.format(
            contest_filter=contest_where,
            sort_field=valid_sort_fields[sort_by],
            sort_order=sort_order,
            limit_clause=f"LIMIT {limit}" if limit else ""
        )
        
        self.logger.debug(f"Executing query: {formatted_query}")
        self.logger.debug(f"Parameters: {params}")
        
        with self.connect_db() as conn:
            cursor = conn.cursor()
            cursor.execute(formatted_query, params)
            results = cursor.fetchall()
            self.logger.debug(f"Retrieved {len(results)} records")
            return results

    def get_band_breakdown(self, callsign=None, contest=None):
        """Retrieve band breakdown for specific callsign or all"""
        if callsign and not self.check_callsign_exists(callsign):
            return None

        # Main query using the latest timestamps and DISTINCT values
        query = """
            WITH latest_scores AS (
                SELECT cs.id, cs.callsign, cs.contest, cs.timestamp
                FROM contest_scores cs
                INNER JOIN (
                    SELECT callsign, contest, MAX(timestamp) as max_ts
                    FROM contest_scores
                    GROUP BY callsign, contest
                ) latest ON cs.callsign = latest.callsign 
                    AND cs.contest = latest.contest
                    AND cs.timestamp = latest.max_ts
            )
            SELECT DISTINCT
                cs.callsign,
                cs.contest,
                cs.timestamp,
                bb.band,
                bb.mode,
                bb.qsos,
                bb.points,
                bb.multipliers
            FROM contest_scores cs
            JOIN latest_scores ls ON cs.id = ls.id
            JOIN band_breakdown bb ON bb.contest_score_id = cs.id
            WHERE bb.band IS NOT NULL
            AND bb.qsos > 0  -- Only include bands with QSOs
        """
        
        params = []
        if callsign:
            query += " AND cs.callsign = ?"
            params.append(callsign)
        if contest:
            query += " AND cs.contest = ?"
            params.append(contest)
        
        query += " ORDER BY cs.callsign, bb.band"
        
        self.logger.debug(f"Executing band breakdown query: {query}")
        self.logger.debug(f"Query parameters: {params}")
        
        with self.connect_db() as conn:
            cursor = conn.cursor()
            
            if callsign:
                contests = self.get_callsign_contests(callsign)
                if contests:
                    print("\nAvailable contests for", callsign + ":")
                    for contest, timestamp in contests:
                        ts = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M')
                        print(f"{contest} ({ts})")
                    print()

            cursor.execute(query, params)
            results = cursor.fetchall()
            self.logger.debug(f"Retrieved {len(results)} band breakdown records")
            return results
    
    def get_qth_details(self, callsign=None, contest=None):
        """Get QTH details for stations"""
        query = """
            WITH latest_scores AS (
                SELECT cs.id, cs.callsign, cs.contest, cs.timestamp
                FROM contest_scores cs
                INNER JOIN (
                    SELECT callsign, contest, MAX(timestamp) as max_ts
                    FROM contest_scores
                    GROUP BY callsign, contest
                ) latest ON cs.callsign = latest.callsign 
                    AND cs.contest = latest.contest
                    AND cs.timestamp = latest.max_ts
            )
            SELECT DISTINCT
                cs.callsign,
                cs.contest,
                cs.timestamp,
                qi.dxcc_country,
                qi.cq_zone,
                qi.iaru_zone,
                qi.arrl_section,
                qi.state_province,
                qi.grid6
            FROM contest_scores cs
            JOIN latest_scores ls ON cs.id = ls.id
            LEFT JOIN qth_info qi ON qi.contest_score_id = cs.id
            WHERE 1=1
        """
        
        params = []
        if callsign:
            query += " AND cs.callsign = ?"
            params.append(callsign)
        if contest:
            query += " AND cs.contest = ?"
            params.append(contest)
        
        query += " ORDER BY cs.callsign, cs.contest"
        
        self.logger.debug(f"Executing QTH query: {query}")
        self.logger.debug(f"Query parameters: {params}")
        
        with self.connect_db() as conn:
            cursor = conn.cursor()
            cursor.execute(query, params)
            results = cursor.fetchall()
            self.logger.debug(f"Retrieved {len(results)} QTH records")
            return results
    
    def get_qth_statistics(self, contest=None):
        """Get statistics about QTH distribution"""
        query = """
            WITH latest_scores AS (
                SELECT cs.id, cs.callsign, cs.contest
                FROM contest_scores cs
                INNER JOIN (
                    SELECT callsign, contest, MAX(timestamp) as max_ts
                    FROM contest_scores
                    GROUP BY callsign, contest
                ) latest ON cs.callsign = latest.callsign 
                    AND cs.contest = latest.contest
                    AND cs.timestamp = latest.max_ts
                WHERE 1=1
                {contest_filter}
            )
            SELECT
                'DXCC Countries' as category,
                COUNT(DISTINCT qi.dxcc_country) as unique_count,
                GROUP_CONCAT(DISTINCT qi.dxcc_country) as items
            FROM latest_scores ls
            JOIN qth_info qi ON qi.contest_score_id = ls.id
            WHERE qi.dxcc_country IS NOT NULL
            UNION ALL
            SELECT 
                'CQ Zones' as category,
                COUNT(DISTINCT qi.cq_zone) as unique_count,
                GROUP_CONCAT(DISTINCT qi.cq_zone) as items
            FROM latest_scores ls
            JOIN qth_info qi ON qi.contest_score_id = ls.id
            WHERE qi.cq_zone IS NOT NULL
            UNION ALL
            SELECT 
                'ARRL Sections' as category,
                COUNT(DISTINCT qi.arrl_section) as unique_count,
                GROUP_CONCAT(DISTINCT qi.arrl_section) as items
            FROM latest_scores ls
            JOIN qth_info qi ON qi.contest_score_id = ls.id
            WHERE qi.arrl_section IS NOT NULL
            UNION ALL
            SELECT 
                'States/Provinces' as category,
                COUNT(DISTINCT qi.state_province) as unique_count,
                GROUP_CONCAT(DISTINCT qi.state_province) as items
            FROM latest_scores ls
            JOIN qth_info qi ON qi.contest_score_id = ls.id
            WHERE qi.state_province IS NOT NULL
        """
        
        contest_where = ""
        params = []
        if contest:
            contest_where = "AND cs.contest = ?"
            params.append(contest)
        
        formatted_query = query.format(contest_filter=contest_where)
        
        with self.connect_db() as conn:
            cursor = conn.cursor()
            cursor.execute(formatted_query, params)
            return cursor.fetchall()
        
    def display_stats(self, stats):
        format_band_stats(stats)

    def display_scores(self, data, show_all=False):
        format_scores(data, show_all)

    def display_band_breakdown(self, data):
        format_band_breakdown(data)

    def get_callsign_contests(self, callsign):
        """Get list of contests for a callsign"""
        query = """
            SELECT DISTINCT contest, timestamp 
            FROM contest_scores 
            WHERE callsign = ?
            ORDER BY timestamp DESC
        """
        with self.connect_db() as conn:
            cursor = conn.cursor()
            cursor.execute(query, (callsign,))
            return cursor.fetchall()

===== contest_server.py =====
#!/usr/bin/env python3
import logging
import urllib.parse
from http.server import HTTPServer
from custom_handler import CustomHandler
from database_handler import ContestDatabaseHandler

class ContestServer:
    def __init__(self, host='127.0.0.1', port=8088, db_path='contest_data.db', debug=False):
        self.host = host
        self.port = port
        self.db_path = db_path
        self.debug = debug
        self.logger = self._setup_logging(debug)
        self.db_handler = ContestDatabaseHandler(db_path)
        
    def _setup_logging(self, debug):
        logger = logging.getLogger('ContestServer')
        logger.setLevel(logging.DEBUG if debug else logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler = logging.StreamHandler()
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        return logger
                
    def start(self):
        """Start the server"""
        try:
            server_address = (self.host, self.port)
            httpd = CustomServer(server_address, 
                               lambda *args, **kwargs: CustomHandler(*args, 
                                                                  debug_mode=self.debug, 
                                                                  **kwargs))
            httpd.db_handler = self.db_handler
            
            self.logger.info(f"Starting server on {self.host}:{self.port}")
            httpd.serve_forever()
            
        except Exception as e:
            self.logger.error(f"Error starting server: {e}")
            raise
        finally:
            self.cleanup()
            
    def cleanup(self):
        """Cleanup resources"""
        try:
            if hasattr(self, 'db_handler'):
                self.db_handler.cleanup()
                self.logger.info("Database handler cleaned up")
                
        except Exception as e:
            self.logger.error(f"Error during cleanup: {e}")

class CustomServer(HTTPServer):
    def __init__(self, *args, db_path='contest_data.db', debug=False, **kwargs):
        super().__init__(*args, **kwargs)
        self.db_handler = ContestDatabaseHandler(db_path)
        self.debug = debug
                
    def server_close(self):
        if hasattr(self, 'db_handler'):
            self.db_handler.cleanup()
        super().server_close()

===== custom_handler.py =====
#!/usr/bin/env python3
from http.server import BaseHTTPRequestHandler
import urllib.parse
import logging
import json
import xml.etree.ElementTree as ET
import re
import traceback

class CustomHandler(BaseHTTPRequestHandler):
    # Standard HTTP response messages
    HTTP_RESPONSES = {
        200: "OK-Full",
        400: "Bad Request - Invalid XML format",
        403: "Forbidden - Unauthorized access",
        404: "Not Found - Invalid endpoint",
        500: "Internal Server Error - Server processing failed"
    }

    def __init__(self, *args, debug_mode=False, **kwargs):
        self.debug_mode = debug_mode
        self.logger = logging.getLogger('CustomHandler')
        super().__init__(*args, **kwargs)

    def debug_print(self, message, data=None):
        """Print debug information if debug mode is enabled"""
        if self.debug_mode:
            debug_info = f"[DEBUG] {message}"
            if data:
                if isinstance(data, (dict, list)):
                    debug_info += f"\n{json.dumps(data, indent=2)}"
                else:
                    debug_info += f"\n{data}"
            self.logger.debug(debug_info)

    def _send_response(self, status_code):
        """Helper method to send standardized HTTP response"""
        self.debug_print(f"Sending response with status code: {status_code}")
        
        response_message = self.HTTP_RESPONSES.get(status_code, "Unknown Error")
        self.debug_print("Response content:", response_message)

        self.send_response(status_code)
        self.send_header('Content-Type', 'text/plain')
        self.send_header('Content-Length', len(response_message))
        self.end_headers()
        self.wfile.write(response_message.encode('utf-8'))

    def log_request_details(self):
        """Log detailed request information"""
        self.debug_print("Request Details:", {
            "path": self.path,
            "method": self.command,
            "headers": dict(self.headers),
            "client_address": self.client_address,
            "request_version": self.request_version
        })

    def validate_xml_data(self, xml_data):
        """Validate XML data format"""
        try:
            xml_docs = re.findall(r'<\?xml.*?</dynamicresults>', xml_data, re.DOTALL)
            if not xml_docs:
                return False
            ET.fromstring(xml_docs[0])
            return True
        except (ET.ParseError, Exception) as e:
            self.debug_print(f"XML validation error: {str(e)}")
            return False

    def do_POST(self):
        """Handle POST requests to /livescore"""
        try:
            self.log_request_details()

            if self.path != '/livescore':
                self.debug_print("Invalid endpoint requested")
                self._send_response(404)
                return

            content_length = int(self.headers.get('Content-Length', 0))
            self.debug_print(f"Content Length: {content_length}")

            post_data = self.rfile.read(content_length).decode('utf-8')
            #ZO
            self.debug_print("Received POST data:", post_data)

            decoded_data = urllib.parse.unquote_plus(post_data)
            #ZO
            self.debug_print("Decoded POST data:", decoded_data)

            if not self.validate_xml_data(decoded_data):
                self.debug_print("Invalid XML data received")
                self._send_response(400)
                return

            if not self.check_authorization():
                self.debug_print("Unauthorized access attempt")
                self._send_response(403)
                return

            db_handler = self.server.db_handler
            db_handler.process_submission(decoded_data)
            
            self._send_response(200)

        except Exception as e:
            error_details = {
                "error": str(e),
                "traceback": traceback.format_exc()
            }
            self.debug_print("Error occurred:", error_details)
            self._send_response(500)

    def do_GET(self):
        """Handle GET requests"""
        self.log_request_details()
        
        if self.path == '/health':
            self.debug_print("Health check requested")
            self._send_response(200)
        else:
            self.debug_print(f"Invalid path requested: {self.path}")
            self._send_response(404)

    def check_authorization(self):
        """Check if the request is authorized"""
        # Example: Check for an API key in headers
        api_key = self.headers.get('X-API-Key')
        # Implement your actual authorization logic here
        return True

===== database_handler.py =====
#!/usr/bin/env python3
import sqlite3
import logging
import xml.etree.ElementTree as ET
import re
import traceback
from datetime import datetime
from callsign_utils import CallsignLookup
from batch_processor import BatchProcessor
from sql_queries import (
    CREATE_CONTEST_SCORES_TABLE,
    CREATE_BAND_BREAKDOWN_TABLE,
    CREATE_QTH_INFO_TABLE,
    INSERT_QTH_INFO,
    INSERT_BAND_BREAKDOWN,
    INSERT_CONTEST_DATA
)

class ContestDatabaseHandler:
    def __init__(self, db_path='contest_data.db'):
        self.db_path = db_path
        self.callsign_lookup = CallsignLookup()
        self.logger = logging.getLogger('ContestDatabaseHandler')
        self.setup_database()
        self.batch_processor = BatchProcessor(self)
        self.batch_processor.start()

    def process_submission(self, xml_data):
        """Add submission to batch instead of processing immediately"""
        self.batch_processor.add_to_batch(xml_data)

    def cleanup(self):
        """Cleanup resources"""
        self.batch_processor.stop()

    def setup_database(self):
        """Create the database tables if they don't exist."""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(CREATE_CONTEST_SCORES_TABLE)
            conn.execute(CREATE_BAND_BREAKDOWN_TABLE)
            conn.execute(CREATE_QTH_INFO_TABLE)

    def parse_xml_data(self, xml_data):
        """Parse XML data and return structured contest data."""
        xml_docs = re.findall(r'<\?xml.*?</dynamicresults>', xml_data, re.DOTALL)
        results = []
        
        for xml_doc in xml_docs:
            try:
                root = ET.fromstring(xml_doc)
                callsign = root.findtext('call', '')
                
                # Get QTH info
                qth_elem = root.find('qth')
                qth_data = {
                    'cq_zone': qth_elem.findtext('cqzone', ''),
                    'iaru_zone': qth_elem.findtext('iaruzone', ''),
                    'arrl_section': qth_elem.findtext('arrlsection', ''),
                    'state_province': qth_elem.findtext('stprvoth', ''),
                    'grid6': qth_elem.findtext('grid6', '')
                } if qth_elem is not None else {}
                
                # Get callsign info
                callsign_info = self.callsign_lookup.get_callsign_info(callsign)
                if callsign_info:
                    qth_data['dxcc_country'] = callsign_info['prefix']
                    qth_data['continent'] = callsign_info['continent']
                    if qth_data.get('cq_zone') in [None, '', '0']:
                        qth_data['cq_zone'] = callsign_info['cq_zone']
                    if qth_data.get('iaru_zone') in [None, '', '0']:
                        qth_data['iaru_zone'] = callsign_info['itu_zone']
                
                # Extract contest data
                contest_data = self._extract_contest_data(root, callsign, qth_data)
                results.append(contest_data)
                
            except ET.ParseError as e:
                self.logger.error(f"Error parsing XML: {e}")
            except Exception as e:
                self.logger.error(f"Error processing data: {e}")
                self.logger.error(traceback.format_exc())
                
        return results

    def _extract_contest_data(self, root, callsign, qth_data):
        """Extract contest data from XML root element."""
        contest_data = {
            'contest': root.findtext('contest', ''),
            'callsign': callsign,
            'timestamp': root.findtext('timestamp', ''),
            'club': root.findtext('club', '').strip(),
            'section': root.find('.//qth/arrlsection').text if root.find('.//qth/arrlsection') is not None else '',
            'score': int(root.findtext('score', 0)),
            'qth': qth_data
        }

        # Extract class attributes
        class_elem = root.find('class')
        if class_elem is not None:
            contest_data.update({
                'power': class_elem.get('power', ''),
                'assisted': class_elem.get('assisted', ''),
                'transmitter': class_elem.get('transmitter', ''),
                'ops': class_elem.get('ops', ''),
                'bands': class_elem.get('bands', ''),
                'mode': class_elem.get('mode', '')
            })

        # Extract breakdown
        breakdown = root.find('breakdown')
        if breakdown is not None:
            contest_data.update(self._extract_breakdown_data(breakdown))

        return contest_data

    def _extract_breakdown_data(self, breakdown):
        """Extract breakdown data from XML breakdown element."""
        try:
            # Handle 'None' text value in XML safely
            def safe_int(elem_text, default=0):
                try:
                    return int(elem_text) if elem_text is not None else default
                except (ValueError, TypeError):
                    return default
    
            # Get total QSOs, points, and multipliers safely
            total_qsos = safe_int(breakdown.findtext('qso[@band="total"][@mode="ALL"]', 0))
            if total_qsos == 0:
                total_qsos = sum(safe_int(elem.text) for elem in breakdown.findall('qso[@band="total"]'))
    
            total_points = safe_int(breakdown.findtext('point[@band="total"][@mode="ALL"]', 0))
            if total_points == 0:
                total_points = sum(safe_int(elem.text) for elem in breakdown.findall('point[@band="total"]'))
    
            total_mults = safe_int(breakdown.findtext('mult[@band="total"][@mode="ALL"]', 0))
            if total_mults == 0:
                total_mults = sum(safe_int(elem.text) for elem in breakdown.findall('mult[@band="total"]'))
    
            data = {
                'qsos': total_qsos,
                'points': total_points,
                'multipliers': total_mults,
                'band_breakdown': []
            }
    
            # Extract per-band breakdown
            for band in ['160', '80', '40', '20', '15', '10']:
                qsos = sum(safe_int(elem.text) for elem in breakdown.findall(f'qso[@band="{band}"]'))
                points = sum(safe_int(elem.text) for elem in breakdown.findall(f'point[@band="{band}"]'))
                multipliers = sum(safe_int(elem.text) for elem in breakdown.findall(f'mult[@band="{band}"]'))
                
                if qsos > 0:
                    data['band_breakdown'].append({
                        'band': band,
                        'mode': 'ALL',
                        'qsos': qsos,
                        'points': points,
                        'multipliers': multipliers
                    })
    
            return data
        except Exception as e:
            self.logger.error(f"Error extracting breakdown data: {e}")
            self.logger.debug(f"Breakdown XML: {ET.tostring(breakdown, encoding='unicode')}")
            raise
    
    def _store_qth_info(self, cursor, contest_score_id, qth_data):
        """Store QTH information in database."""
        cursor.execute(INSERT_QTH_INFO, (
            contest_score_id,
            qth_data.get('dxcc_country', ''),
            qth_data.get('continent', ''),  # Fixed typo in variable name
            qth_data.get('cq_zone', ''),
            qth_data.get('iaru_zone', ''),
            qth_data.get('arrl_section', ''),
            qth_data.get('state_province', ''),
            qth_data.get('grid6', '')
        ))

    def store_data(self, contest_data):
        """Store contest data in the database."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            for data in contest_data:
                try:
                    # Insert main contest data
                    cursor.execute(INSERT_CONTEST_DATA, (
                        data['timestamp'], data['contest'], data['callsign'],
                        data.get('power', ''), data.get('assisted', ''),
                        data.get('transmitter', ''), data.get('ops', ''),
                        data.get('bands', ''), data.get('mode', ''),
                        data.get('overlay', ''), data['club'], data['section'],
                        data['score'], data.get('qsos', 0), data.get('multipliers', 0),
                        data.get('points', 0)
                    ))
                    
                    contest_score_id = cursor.lastrowid
                    
                    # Store QTH info
                    self._store_qth_info(cursor, contest_score_id, data['qth'])
                    
                    # Store band breakdown
                    self._store_band_breakdown(cursor, contest_score_id, data.get('band_breakdown', []))
                    
                    conn.commit()
                    
                except Exception as e:
                    self.logger.error(f"Error storing data for {data['callsign']}: {e}")
                    self.logger.error(traceback.format_exc())
                    raise

    
    def _store_band_breakdown(self, cursor, contest_score_id, band_breakdown):
        """Store band breakdown information in database."""
        for band_data in band_breakdown:
            cursor.execute(INSERT_BAND_BREAKDOWN, (
                contest_score_id,
                band_data['band'],
                band_data['mode'],
                band_data['qsos'],
                band_data['points'],
                band_data['multipliers']
            ))

===== database_manager.py =====
#!/usr/bin/env python3
import sqlite3
import argparse
import sys
from tabulate import tabulate
from sql_queries import (
    CREATE_INDEXES,
    GET_SMALL_CONTESTS,
    DELETE_CONTEST_RECORDS,
    GET_INDEX_INFO,
    EXAMPLE_QUERIES,
    DELETE_BAND_BREAKDOWN_BY_CONTEST_SCORE_ID,
    DELETE_QTH_INFO_BY_CONTEST_SCORE_ID,
    DELETE_CONTEST_SCORES_BY_CONTEST
)

class DatabaseManager:
    def __init__(self, db_path):
        self.db_path = db_path

    def explain_query(self, query):
        """Analyze and explain query execution plan"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # First get the explain plan
                print("\nExecution Plan:")
                cursor.execute(f"EXPLAIN QUERY PLAN {query}")
                plan_rows = cursor.fetchall()
                for row in plan_rows:
                    print(f"id: {row[0]}, parent: {row[1]}, notused: {row[2]}, detail: {row[3]}")
                
                # Then run the query with actual execution statistics
                print("\nQuery Statistics:")
                cursor.execute(f"EXPLAIN {query}")
                stats_rows = cursor.fetchall()
                for row in stats_rows:
                    print(row[0])
                
                # Execute the query to show results
                print("\nQuery Results:")
                cursor.execute(query)
                results = cursor.fetchall()
                if results:
                    print(f"Found {len(results)} rows")
                    # Display first few results
                    for row in results[:5]:
                        print(row)
                    if len(results) > 5:
                        print("...")
                else:
                    print("No results found")
                    
        except sqlite3.Error as e:
            print(f"Error analyzing query: {e}", file=sys.stderr)
            sys.exit(1)

    def setup_indexes(self, analyze=True):
        """Create indexes on the contest database"""
        print(f"Setting up indexes on database: {self.db_path}")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                for cmd in CREATE_INDEXES:
                    print(f"Creating index...")
                    print(cmd.replace('\n', ' ').strip())
                    conn.execute(cmd)
                    print("Success!")
                    print()
                
                if analyze:
                    print("Analyzing database...")
                    conn.execute("ANALYZE contest_scores")
                    conn.execute("ANALYZE band_breakdown")
                    conn.execute("ANALYZE qth_info")
                    print("Analysis complete!")

            print("\nAll indexes created successfully!")
            
        except sqlite3.Error as e:
            print(f"Error creating indexes: {e}", file=sys.stderr)
            sys.exit(1)

    def cleanup_small_contests(self, min_participants):
        """Remove contests that have fewer than specified number of participants"""
        print(f"\nLooking for contests with fewer than {min_participants} participants...")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # First, get a list of contests and their participant counts
                cursor.execute(GET_SMALL_CONTESTS, (min_participants,))
                small_contests = cursor.fetchall()
                
                if not small_contests:
                    print("No contests found with fewer than " +
                          f"{min_participants} participants.")
                    return
                
                # Display contests that will be removed
                headers = ['Contest', 'Participants']
                print("\nContests to be removed:")
                print(tabulate(small_contests, headers=headers, tablefmt='grid'))
                
                # Ask for confirmation
                response = input("\nDo you want to remove these contests? (yes/no): ")
                if response.lower() != 'yes':
                    print("Operation cancelled.")
                    return
                
                # Delete process
                print("\nRemoving contests...")
                for contest, _ in small_contests:
                    print(f"Processing {contest}...")
                    
                    # Get contest_score_ids for this contest
                    cursor.execute(DELETE_CONTEST_RECORDS, (contest,))
                    score_ids = [row[0] for row in cursor.fetchall()]
                    
                    if score_ids:
                        # Delete from band_breakdown
                        cursor.execute(DELETE_BAND_BREAKDOWN_BY_CONTEST_SCORE_ID, (contest,))
                        bb_count = cursor.rowcount
                        
                        # Delete from qth_info
                        cursor.execute(DELETE_QTH_INFO_BY_CONTEST_SCORE_ID, (contest,))
                        qth_count = cursor.rowcount
                        
                        # Delete from contest_scores
                        cursor.execute(DELETE_CONTEST_SCORES_BY_CONTEST, (contest,))
                        cs_count = cursor.rowcount
                        
                        print(f"Removed {cs_count} score entries, " +
                              f"{bb_count} band breakdown entries, " +
                              f"{qth_count} QTH info entries")
                    
                conn.commit()
                print("\nCleanup complete!")
                
        except sqlite3.Error as e:
            print(f"Database error: {e}", file=sys.stderr)
            sys.exit(1)

    def reindex_database(self):
        """Rebuild all indexes on the database"""
        print(f"Rebuilding indexes on database: {self.db_path}")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                print("Reindexing contest_scores table...")
                conn.execute("REINDEX contest_scores")
                
                print("Reindexing band_breakdown table...")
                conn.execute("REINDEX band_breakdown")
                
                print("Reindexing qth_info table...")
                conn.execute("REINDEX qth_info")
                
            print("\nAll indexes rebuilt successfully!")
            
        except sqlite3.Error as e:
            print(f"Error rebuilding indexes: {e}", file=sys.stderr)
            sys.exit(1)

    def list_indexes(self):
        """List all indexes in the database"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute(GET_INDEX_INFO)
                indexes = cursor.fetchall()
                
                if indexes:
                    headers = ["Table", "Index Name", "Columns"]
                    print("\nDatabase Indexes:")
                    print(tabulate(indexes, headers=headers, tablefmt='grid'))
                else:
                    print("\nNo indexes found in the database.")
                
        except sqlite3.Error as e:
            print(f"Error listing indexes: {e}", file=sys.stderr)
            sys.exit(1)

def main():
    parser = argparse.ArgumentParser(
        description='Contest Database Management Tool',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  Create new indexes:
    %(prog)s --db contest_data.db --create-indexes
  
  Rebuild existing indexes:
    %(prog)s --db contest_data.db --reindex
  
  List existing indexes:
    %(prog)s --db contest_data.db --list
  
  Analyze query performance:
    %(prog)s --db contest_data.db --explain latest_scores
    
  Remove small contests:
    %(prog)s --db contest_data.db --cleanup-contests 5
        """)
    
    parser.add_argument('--db', default='contest_data.db',
                      help='Database file path (default: contest_data.db)')
    
    action_group = parser.add_mutually_exclusive_group(required=True)
    action_group.add_argument('--create-indexes', action='store_true',
                          help='Create new indexes on the database')
    action_group.add_argument('--reindex', action='store_true',
                          help='Rebuild existing indexes')
    action_group.add_argument('--list', action='store_true',
                          help='List existing indexes')
    action_group.add_argument('--explain',
                          choices=list(EXAMPLE_QUERIES.keys()),
                          help='Analyze query execution plan for example queries')
    action_group.add_argument('--cleanup-contests', type=int, metavar='MIN_PARTICIPANTS',
                          help='Remove contests with fewer than MIN_PARTICIPANTS participants')
    
    parser.add_argument('--no-analyze', action='store_true',
                      help='Skip analyzing the database after creating indexes')
    
    args = parser.parse_args()
    
    db_manager = DatabaseManager(args.db)
    
    if args.cleanup_contests is not None:
        if args.cleanup_contests < 1:
            print("Error: Minimum participants must be at least 1", file=sys.stderr)
            sys.exit(1)
        db_manager.cleanup_small_contests(args.cleanup_contests)
    elif args.create_indexes:
        db_manager.setup_indexes(not args.no_analyze)
    elif args.reindex:
        db_manager.reindex_database()
    elif args.list:
        db_manager.list_indexes()
    elif args.explain:
        query = EXAMPLE_QUERIES[args.explain]
        print(f"\nAnalyzing query: {args.explain}")
        print("Query text:")
        print(query)
        db_manager.explain_query(query)

if __name__ == "__main__":
    main()

===== display_utils.py =====
#!/usr/bin/env python3
from datetime import datetime
from tabulate import tabulate

def format_band_stats(stats):
    """Format and display database statistics"""
    # Display total stats
    total_stats = stats["total_stats"]
    print("\n=== Overall Statistics ===")
    print(f"Unique Stations: {total_stats[0]}")
    print(f"Number of Contests: {total_stats[1]}")
    print(f"Total Uploads: {total_stats[2]}")
    print(f"Total QSOs: {total_stats[3]}")

    # Display contest stats
    print("\n=== Contest Statistics ===")
    headers = ['Contest', 'Participants', 'Uploads', 'First Upload', 'Last Upload', 'High Score', 'Total QSOs']
    contest_data = []
    for row in stats["contest_counts"]:
        formatted_row = list(row)
        # Format timestamps
        formatted_row[3] = datetime.strptime(row[3], '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M')
        formatted_row[4] = datetime.strptime(row[4], '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M')
        contest_data.append(formatted_row)
    print(tabulate(contest_data, headers=headers, tablefmt='grid'))

    # Display band statistics by contest
    print("\n=== Band Statistics by Contest ===")
    headers = ['Contest', 'Stations', 
              '160m Q/P/M', '80m Q/P/M', '40m Q/P/M', 
              '20m Q/P/M', '15m Q/P/M', '10m Q/P/M']
    
    band_data = []
    for row in stats["band_stats"]:
        formatted_row = [
            row[0],  # Contest
            row[1],  # Stations
            f"{row[2]}/{row[3]}/{row[4]}" if row[2] or row[3] or row[4] else "-",  # 160m
            f"{row[5]}/{row[6]}/{row[7]}" if row[5] or row[6] or row[7] else "-",  # 80m
            f"{row[8]}/{row[9]}/{row[10]}" if row[8] or row[9] or row[10] else "-",  # 40m
            f"{row[11]}/{row[12]}/{row[13]}" if row[11] or row[12] or row[13] else "-",  # 20m
            f"{row[14]}/{row[15]}/{row[16]}" if row[14] or row[15] or row[16] else "-",  # 15m
            f"{row[17]}/{row[18]}/{row[19]}" if row[17] or row[18] or row[19] else "-",  # 10m
        ]
        band_data.append(formatted_row)
    
    print(tabulate(band_data, headers=headers, tablefmt='grid'))

def format_scores(data, show_all=False):
    """Format and display contest scores"""
    headers = ['Timestamp', 'Contest', 'Callsign', 'Power', 'Score', 'QSOs', 
              'Mults', 'Club', 'Section', 'Assisted', 'Mode']

    if not data:
        print("No records found.")
        return

    formatted_data = []
    for row in data:
        formatted_row = list(row)
        # Format timestamp
        formatted_row[0] = datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M')
        
        # Truncate long fields if not show_all
        if not show_all:
            for i, field in enumerate(formatted_row):
                if isinstance(field, str) and len(field) > 20:
                    formatted_row[i] = field[:17] + '...'
        
        formatted_data.append(formatted_row)

    print(tabulate(formatted_data, headers=headers, tablefmt='grid'))

def format_band_breakdown(data):
    """Format and display band breakdown data"""
    if data is None:
        return

    headers = ['Callsign', 'Contest', 'Timestamp', 'Band', 'Mode', 'QSOs', 'Points', 'Multipliers']
    
    if not data:
        print("No band breakdown records found.")
        return
    
    # Format the timestamp in the data
    formatted_data = []
    current_callsign = None
    current_timestamp = None
    
    for row in data:
        formatted_row = list(row)
        
        # Add a blank line between different callsigns or timestamps
        if (current_callsign is not None and current_callsign != row[0]) or \
           (current_timestamp is not None and current_timestamp != row[2]):
            formatted_data.append(['-'*10, '-'*10, '-'*16, '-'*4, '-'*4, '-'*4, '-'*6, '-'*11])
        
        current_callsign = row[0]
        current_timestamp = row[2]
        
        # Format timestamp (index 2)
        formatted_row[2] = datetime.strptime(row[2], '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M')
        formatted_data.append(formatted_row)
    
    print(tabulate(formatted_data, headers=headers, tablefmt='grid'))

def format_number(num):
    """Format numbers with thousands separator"""
    return f"{num:,}" if num else "0"

def format_qth_details(data):
    """Format and display QTH information"""
    if not data:
        print("No QTH records found.")
        return

    headers = ['Callsign', 'Contest', 'Timestamp', 'Country', 'CQ Zone', 
              'IARU Zone', 'ARRL Section', 'State/Province', 'Grid']
    
    formatted_data = []
    current_call = None
    
    for row in data:
        # Format timestamp
        formatted_row = list(row)
        formatted_row[2] = datetime.strptime(row[2], '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d %H:%M')
        
        # Add separator line between different callsigns
        if current_call is not None and current_call != row[0]:
            formatted_data.append(['-' * 10] * len(headers))
        
        current_call = row[0]
        formatted_data.append(formatted_row)
    
    print(tabulate(formatted_data, headers=headers, tablefmt='grid'))

def format_qth_statistics(stats):
    """Format and display QTH statistics"""
    if not stats:
        print("No QTH statistics available.")
        return

    print("\n=== QTH Statistics ===")
    for category, count, items in stats:
        print(f"\n{category}:")
        print(f"Total unique: {count}")
        if items:
            item_list = items.split(',')
            # Format items in columns
            col_width = max(len(item) for item in item_list) + 2
            cols = max(1, 80 // col_width)  # Limit to 80 chars width
            for i in range(0, len(item_list), cols):
                print("".join(item.ljust(col_width) for item in item_list[i:i+cols]))

===== gunicorn_config.py =====
import os
import multiprocessing

# Create logs directory if it doesn't exist
log_dir = "/opt/livescore/logs"
os.makedirs(log_dir, exist_ok=True)

# Basic configurations
bind = "127.0.0.1:8089"
workers = multiprocessing.cpu_count() * 2 + 1
worker_class = "sync"
timeout = 120
keepalive = 5

# Logging
errorlog = os.path.join(log_dir, "gunicorn-error.log")
accesslog = os.path.join(log_dir, "gunicorn-access.log")
loglevel = "error"  

# Ensure proper permissions
capture_output = True
enable_stdio_inheritance = True

# Process naming
proc_name = 'livescore-pilot'

# Graceful timeout
graceful_timeout = 30

# Trust the X-Forwarded-For headers from local proxies
forwarded_allow_ips = '*'


===== livescore-pilot.service =====
[Unit]
Description=Livescore Pilot Gunicorn Service
After=network.target

[Service]
User=root
Group=root
Environment="PATH=/usr/local/bin:/usr/bin:/bin"
Environment="PYTHONPATH=/opt/livescore"
WorkingDirectory=/opt/livescore
ExecStart=/usr/local/bin/gunicorn -c gunicorn_config.py web_interface:app
Restart=always
RestartSec=10

# Logging
StandardOutput=append:/opt/livescore/logs/service-output.log
StandardError=append:/opt/livescore/logs/service-error.log

[Install]
WantedBy=multi-user.target

===== livescore.py =====
#!/usr/bin/env python3
import argparse
import logging
import sys
from contest_server import ContestServer
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from maintenance_task import perform_maintenance
import os

def setup_logging(debug_mode, log_file):
    """Setup logging configuration"""
    log_level = logging.DEBUG if debug_mode else logging.INFO
    
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    )

    file_handler = logging.FileHandler(log_file)
    file_handler.setFormatter(formatter)

    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)

    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)

    return root_logger

def run_maintenance(db_path, logger):
    """Run maintenance tasks with logging"""
    try:
        logger.info("Starting scheduled maintenance tasks...")
        
        # Create maintenance directories if they don't exist
        backup_dir = "./backups"
        reports_dir = "./reports"
        archive_dir = "./archive"
        for directory in [backup_dir, reports_dir, archive_dir]:
            os.makedirs(directory, exist_ok=True)

        # Run maintenance with dry_run=False
        perform_maintenance(db_path, dry_run=False)
        logger.info("Scheduled maintenance completed successfully")
        
    except Exception as e:
        logger.error(f"Error during scheduled maintenance: {e}")
        logger.exception("Maintenance task error details:")

def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description='Contest Data Server')
    parser.add_argument('-d', '--debug', action='store_true',
                      help='Enable debug mode')
    parser.add_argument('--host', default='127.0.0.1',
                      help='Host to bind to (default: 127.0.0.1)')
    parser.add_argument('--port', type=int, default=8088,
                      help='Port to bind to (default: 8088)')
    parser.add_argument('--log-file', default='contest_server.log',
                      help='Log file path (default: contest_server.log)')
    parser.add_argument('--db-file', default='contest_data.db',
                      help='Database file path (default: contest_data.db)')
    parser.add_argument('--maintenance-hour', type=int, default=2,
                      help='Hour to run maintenance (24-hour format, default: 2)')
    parser.add_argument('--maintenance-minute', type=int, default=0,
                      help='Minute to run maintenance (default: 0)')
    return parser.parse_args()

def main():
    # Parse command line arguments
    args = parse_arguments()
    
    # Setup logging
    logger = setup_logging(args.debug, args.log_file)
    
    # Log startup information
    logging.info("Server starting up with configuration:")
    logging.info(f"Host: {args.host}")
    logging.info(f"Port: {args.port}")
    logging.info(f"Debug Mode: {'ON' if args.debug else 'OFF'}")
    logging.info(f"Log File: {args.log_file}")
    logging.info(f"Database File: {args.db_file}")
    logging.info(f"Maintenance Time: {args.maintenance_hour:02d}:{args.maintenance_minute:02d}")
    
    # Initialize scheduler
    scheduler = BackgroundScheduler()
    
    # Add maintenance job
    trigger = CronTrigger(
        hour=args.maintenance_hour,
        minute=args.maintenance_minute
    )
    
    scheduler.add_job(
        run_maintenance,
        trigger=trigger,
        args=[args.db_file, logger],
        id='maintenance_job',
        name='Database Maintenance',
        misfire_grace_time=3600  # Allow job to run up to 1 hour late
    )
    
    # Start the scheduler
    scheduler.start()
    logger.info(f"Scheduled maintenance job for {args.maintenance_hour:02d}:{args.maintenance_minute:02d}")
    
    try:
        # Create and start server
        server = ContestServer(args.host, args.port, args.db_file, args.debug)
        server.start()
        
    except KeyboardInterrupt:
        logger.info("Received shutdown signal")
    except Exception as e:
        logger.error(f"Error starting server: {e}")
        logger.exception("Server error details:")
        raise
    finally:
        # Cleanup
        logger.info("Shutting down scheduler...")
        scheduler.shutdown()
        if 'server' in locals():
            server.cleanup()
        logger.info("Server shutdown complete")

if __name__ == "__main__":
    main()

===== maintenance_task.py =====
#!/usr/bin/env python3
import sqlite3
import argparse
import logging
from datetime import datetime, timedelta
import os
import shutil
from sql_queries import (
    CHECK_QSO_CONSISTENCY,
    COUNT_ORPHANED_BAND_BREAKDOWN,
    COUNT_ORPHANED_QTH_INFO,
    ANALYZE_ORPHANED_BAND_BREAKDOWN,
    ANALYZE_ORPHANED_QTH_INFO,
    DELETE_ORPHANED_BAND_BREAKDOWN,
    DELETE_ORPHANED_QTH_INFO,
    FIND_SMALL_CONTESTS,
    GET_OLD_RECORDS,
    DELETE_BAND_BREAKDOWN_BY_CONTEST_SCORE_ID,
    DELETE_QTH_INFO_BY_CONTEST_SCORE_ID,
    DELETE_CONTEST_SCORES_BY_CONTEST,
    GET_ARCHIVE_RECORDS
)

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_qso_consistency(cursor):
    """
    Check QSO count consistency while accounting for stations that only report totals.
    Returns a tuple of (true_inconsistencies, total_without_breakdown)
    """
    cursor.execute(CHECK_QSO_CONSISTENCY)
    true_inconsistencies = cursor.fetchall()

    cursor.execute(COUNT_ORPHANED_BAND_BREAKDOWN)
    total_without_breakdown = cursor.fetchone()[0]

    return true_inconsistencies, total_without_breakdown

def analyze_orphaned_records(cursor):
    """Analyze orphaned records to provide detailed information"""
    try:
        # Analyze orphaned band breakdown records
        cursor.execute(ANALYZE_ORPHANED_BAND_BREAKDOWN)
        bb_analysis = cursor.fetchall()

        # Analyze orphaned QTH info records
        cursor.execute(ANALYZE_ORPHANED_QTH_INFO)
        qth_analysis = cursor.fetchall()

        return {'band_breakdown': bb_analysis, 'qth_info': qth_analysis}

    except Exception as e:
        logger.error(f"Error analyzing orphaned records: {e}")
        return None

def handle_orphaned_records(cursor, dry_run=True, threshold=1000):
    """
    Handle orphaned records with safeguards
    """
    # Get counts
    cursor.execute(COUNT_ORPHANED_BAND_BREAKDOWN)
    orphaned_bb = cursor.fetchone()[0]
    
    cursor.execute(COUNT_ORPHANED_QTH_INFO)
    orphaned_qth = cursor.fetchone()[0]

    if orphaned_bb > 0 or orphaned_qth > 0:
        logger.warning(f"Found orphaned records:")
        logger.warning(f"  Band breakdown: {orphaned_bb:,}")
        logger.warning(f"  QTH info: {orphaned_qth:,}")

        # Get sample analysis
        analysis = analyze_orphaned_records(cursor)
        if analysis:
            bb_analysis = analysis['band_breakdown']
            qth_analysis = analysis['qth_info']

            logger.info("\nAnalysis of orphaned band breakdown records (top 10):")
            for record in bb_analysis:
                logger.info(f"Contest Score ID {record[0]}: {record[1]} records, {record[2]} QSOs")
                logger.info(f"  Bands: {record[3]}")
                logger.info(f"  QSO range: {record[4]} - {record[5]}")

            logger.info("\nAnalysis of orphaned QTH info records (top 10):")
            for record in qth_analysis:
                logger.info(f"Contest Score ID {record[0]}: {record[1]}, {record[2]}, CQ:{record[3]}, IARU:{record[4]}")

        # Safety check - if too many orphaned records, require manual confirmation
        if orphaned_bb > threshold or orphaned_qth > threshold:
            logger.warning("\nWARNING: Large number of orphaned records detected!")
            logger.warning("This might indicate a database issue that needs investigation.")
            logger.warning("Please run with --analyze-only first to review the analysis.")
            return False

        if not dry_run:
            logger.info("\nRemoving orphaned records...")
            # Begin transaction
            cursor.execute("BEGIN TRANSACTION")
            try:
                # Delete orphaned records
                cursor.execute(DELETE_ORPHANED_BAND_BREAKDOWN)
                bb_deleted = cursor.rowcount
                
                cursor.execute(DELETE_ORPHANED_QTH_INFO)
                qth_deleted = cursor.rowcount
                
                cursor.execute("COMMIT")
                logger.info(f"Successfully removed {bb_deleted:,} band breakdown and {qth_deleted:,} QTH info orphaned records")
                return True
            except Exception as e:
                cursor.execute("ROLLBACK")
                logger.error(f"Error during orphaned record cleanup: {e}")
                return False
        else:
            logger.info("\nDry run - no records were deleted")
            return True
    else:
        logger.info("No orphaned records found")
        return True

def perform_maintenance(db_path, dry_run):
    """
    Performs enhanced maintenance tasks with improved database locking handling.
    Uses SQLite-compatible query patterns.
    """
    try:
        with sqlite3.connect(db_path, timeout=30) as conn:
            conn.execute("PRAGMA busy_timeout = 30000")  # 30 second timeout
            cursor = conn.cursor()

            # 1. First perform read-only analysis
            logger.info("Checking for orphaned records...")
            orphaned_analysis = analyze_orphaned_records(cursor)
            if orphaned_analysis:
                logger.info("Analysis completed, proceeding with maintenance")

            # 2. Perform QSO consistency check (runs in both dry-run and normal modes)
            logger.info("Checking QSO count consistency...")
            inconsistent_qsos, logs_without_breakdown = check_qso_consistency(cursor)
            logger.info(f"Found {logs_without_breakdown} logs without band breakdown data (this is normal)")
            if inconsistent_qsos:
                logger.warning(f"Found {len(inconsistent_qsos)} records with QSO count mismatches")

            # 3. Perform write operations in a single transaction (skipped in dry-run mode)
            if not dry_run:
                cursor.execute("BEGIN IMMEDIATE")  # Get exclusive lock
                try:
                    # Handle orphaned records cleanup
                    cursor.execute(DELETE_ORPHANED_BAND_BREAKDOWN)
                    bb_deleted = cursor.rowcount
                    cursor.execute(DELETE_ORPHANED_QTH_INFO)
                    qth_deleted = cursor.rowcount
                    logger.info(f"Removed {bb_deleted} orphaned band records and {qth_deleted} orphaned QTH records")

                    # Clean up small contests
                    cursor.execute(FIND_SMALL_CONTESTS)
                    contests_to_delete = cursor.fetchall()

                    for contest, num_callsigns in contests_to_delete:
                        logger.info(f"Removing contest: {contest} ({num_callsigns} callsigns)")
                        # Get IDs first
                        cursor.execute(GET_OLD_RECORDS, (contest,))
                        contest_ids = [row[0] for row in cursor.fetchall()]
                        
                        # Delete related records
                        if contest_ids:
                            delete_in_batches(cursor, DELETE_BAND_BREAKDOWN_BY_CONTEST_SCORE_ID, contest_ids)
                            delete_in_batches(cursor, DELETE_QTH_INFO_BY_CONTEST_SCORE_ID, contest_ids)
                            
                        # Delete main records
                        cursor.execute(DELETE_CONTEST_SCORES_BY_CONTEST, (contest,))
                        logger.info(f"Deleted contest '{contest}' and all related records")

                    # Delete old records
                    threshold_date = datetime.now() - timedelta(days=3)
                    cursor.execute(GET_OLD_RECORDS, (threshold_date,))
                    old_ids = [row[0] for row in cursor.fetchall()]
                    
                    if old_ids:
                        # Delete old records in batches
                        delete_in_batches(cursor, DELETE_BAND_BREAKDOWN_BY_CONTEST_SCORE_ID, old_ids)
                        delete_in_batches(cursor, DELETE_QTH_INFO_BY_CONTEST_SCORE_ID, old_ids)
                        delete_in_batches(cursor, "contest_scores", "id", old_ids)
                        logger.info(f"Deleted {len(old_ids)} old contest records and related data")

                    # File System Maintenance
                    backup_dir = "./backups"
                    reports_dir = "./reports"
                    archive_dir = "./archive"

                    for directory in [backup_dir, reports_dir, archive_dir]:
                        os.makedirs(directory, exist_ok=True)

                    cleanup_old_files(backup_dir, 30, dry_run, "backup")
                    cleanup_old_files(reports_dir, 3, dry_run, "report")

                    # Archive old records
                    archive_old_records(cursor, archive_dir, conn)

                    # Commit the transaction
                    cursor.execute("COMMIT")
                    logger.info("Database cleanup and file system maintenance completed successfully")

                except Exception as e:
                    cursor.execute("ROLLBACK")
                    logger.error(f"Error during maintenance, rolling back: {e}")
                    raise

                # 4. Perform optimization as a separate operation
                try:
                    optimize_result = optimize_database(db_path)
                    if not optimize_result:
                        logger.warning("Database optimization skipped due to locks")
                except Exception as e:
                    logger.error(f"Optimization error (non-fatal): {e}")

            # 5. Final Statistics
            cursor.execute("SELECT COUNT(*) FROM contest_scores")
            total_scores = cursor.fetchone()[0]
            cursor.execute("SELECT COUNT(DISTINCT contest) FROM contest_scores")
            total_contests = cursor.fetchone()[0]
            cursor.execute("SELECT COUNT(DISTINCT callsign) FROM contest_scores")
            total_stations = cursor.fetchone()[0]

            # Get orphaned records count
            cursor.execute(COUNT_ORPHANED_BAND_BREAKDOWN)
            orphaned_bb = cursor.fetchone()[0]
            cursor.execute(COUNT_ORPHANED_QTH_INFO)
            orphaned_qth = cursor.fetchone()[0]

            logger.info("\nMaintenance Summary:")
            logger.info(f"Total Contests: {total_contests}")
            logger.info(f"Total Stations: {total_stations}")
            logger.info(f"Total Score Records: {total_scores}")
            logger.info(f"Orphaned Records Found: {orphaned_bb + orphaned_qth}")
            logger.info(f"Logs without Band Breakdown: {logs_without_breakdown}")
            logger.info(f"True QSO Inconsistencies: {len(inconsistent_qsos)}")

        return True

    except sqlite3.Error as e:
        logger.error(f"Database error: {e}")
        return False
    except Exception as e:
        logger.error(f"Error: {e}")
        return False

def cleanup_old_files(directory, days, dry_run, file_type):
    """Helper function to clean up old files"""
    logger.info(f"Cleaning up old {file_type} files...")
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        if os.path.isfile(file_path):
            file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(file_path))
            if file_age > timedelta(days=days):
                if dry_run:
                    logger.info(f"Would delete old {file_type} file: {file_path}")
                else:
                    os.remove(file_path)
                    logger.info(f"Deleted old {file_type} file: {file_path}")

def delete_in_batches(cursor, query, ids, batch_size=999):
    for i in range(0, len(ids), batch_size):
        batch = ids[i:i + batch_size]
        cursor.execute(query, (','.join(map(str, batch)),))

def optimize_database(db_path):
    """Perform database optimization with retry logic"""
    max_retries = 3
    retry_delay = 5  # seconds
    
    for attempt in range(max_retries):
        try:
            # First run ANALYZE and REINDEX which can be in a transaction
            with sqlite3.connect(db_path, timeout=30) as conn:
                conn.execute("PRAGMA busy_timeout = 30000")
                logger.info("Running ANALYZE...")
                conn.execute("ANALYZE")
                logger.info("Running REINDEX...")
                conn.execute("REINDEX")
                
            # Now run VACUUM with a fresh connection
            with sqlite3.connect(db_path, timeout=30) as conn:
                logger.info("Running VACUUM...")
                conn.execute("VACUUM")
                return True
                
        except sqlite3.Error as e:
            if "database is locked" in str(e) and attempt < max_retries - 1:
                logger.warning(f"Database locked, retrying in {retry_delay} seconds...")
                time.sleep(retry_delay)
                continue
            logger.error(f"Database optimization error: {e}")
            return False
            
    return False
        
def archive_old_records(cursor, archive_dir, conn):
    """Helper function to archive old records"""
    logger.info("Archiving old contest records...")
    cursor.execute(GET_ARCHIVE_RECORDS, (datetime.now() - timedelta(days=365),))
    old_records = cursor.fetchall()

    if old_records:
        for record_id, contest, timestamp in old_records:
            archive_file = os.path.join(archive_dir, f"{contest}_{record_id}.txt")
            with open(archive_file, 'w') as f:
                f.write(f"Archived Record ID: {record_id}\nContest: {contest}\nTimestamp: {timestamp}\n")
            cursor.execute(DELETE_BAND_BREAKDOWN_BY_CONTEST_SCORE_ID, (record_id,))
            cursor.execute(DELETE_QTH_INFO_BY_CONTEST_SCORE_ID, (record_id,))
            cursor.execute("DELETE FROM contest_scores WHERE id = ?", (record_id,))
            logger.info(f"Archived and deleted record {record_id} for contest '{contest}'")
        conn.commit()
        logger.info("Archiving completed")
    else:
        logger.info("No old records found to archive")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Enhanced Maintenance Script for Contest Database.")
    parser.add_argument("--db", required=True, help="Path to the SQLite database file.")
    parser.add_argument("--dry-run", action="store_true", help="Preview the changes without making any deletions or modifications.")
    parser.add_argument("--analyze-only", action="store_true", help="Only analyze orphaned records without deletion.")
    parser.add_argument("--threshold", type=int, default=1000, help="Safety threshold for automatic orphaned record deletion.")
    args = parser.parse_args()

    logger.info(f"Starting maintenance script on database: {args.db}")
    logger.info(f"Dry-run mode: {'ON' if args.dry_run else 'OFF'}")
    
    perform_maintenance(args.db, args.dry_run)
    logger.info("Maintenance script finished.")

===== mqtt_distributor.py =====
#!/usr/bin/env python3
import paho.mqtt.client as mqtt
import json
import logging
import time
from datetime import datetime
import signal
import sys
import sqlite3
import argparse
import traceback

class ContestDataSubscriber:
    """Base class for subscribing to contest database updates"""
    def __init__(self, db_path, polling_interval=5):
        self.db_path = db_path
        self.polling_interval = polling_interval
        self.last_processed_id = 0
        self.running = True
        self.last_check_time = datetime.now()
        
        # Setup signal handlers
        signal.signal(signal.SIGINT, self.handle_shutdown)
        signal.signal(signal.SIGTERM, self.handle_shutdown)

    def handle_shutdown(self, signum, frame):
        """Handle shutdown signals gracefully"""
        self.logger.info("Received shutdown signal, stopping...")
        self.running = False

    def get_new_records(self):
        """Fetch new records from the database since last check"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # On first run (last_processed_id = 0), get records from last 5 minutes only
                if self.last_processed_id == 0:
                    self.logger.info("First run - getting records from last 5 minutes only")
                    cursor.execute("""
                        SELECT 
                            cs.id,
                            cs.timestamp,
                            cs.contest,
                            cs.callsign,
                            cs.score,
                            cs.qsos,
                            cs.multipliers,
                            cs.power,
                            cs.assisted,
                            cs.transmitter
                        FROM contest_scores cs
                        WHERE cs.timestamp >= datetime('now', '-5 minutes')
                        ORDER BY cs.id
                    """)
                else:
                    # After first run, get records since last processed ID
                    cursor.execute("""
                        SELECT 
                            cs.id,
                            cs.timestamp,
                            cs.contest,
                            cs.callsign,
                            cs.score,
                            cs.qsos,
                            cs.multipliers,
                            cs.power,
                            cs.assisted,
                            cs.transmitter
                        FROM contest_scores cs
                        WHERE cs.id > ?
                        ORDER BY cs.id
                    """, (self.last_processed_id,))
                
                scores = cursor.fetchall()
                
                if scores:
                    self.logger.info(f"Found {len(scores)} new records")
                    if self.last_processed_id == 0:
                        self.logger.info("Processing initial records from last 5 minutes")
                    
                # If we have new scores, get their associated data
                results = []
                for score in scores:
                    score_id = score[0]
                    
                    # Get band breakdown
                    cursor.execute("""
                        SELECT band, mode, qsos, points, multipliers
                        FROM band_breakdown
                        WHERE contest_score_id = ?
                    """, (score_id,))
                    band_data = cursor.fetchall()
                    
                    # Get QTH info
                    cursor.execute("""
                        SELECT dxcc_country, cq_zone, iaru_zone, 
                               arrl_section, state_province, grid6
                        FROM qth_info
                        WHERE contest_score_id = ?
                    """, (score_id,))
                    qth_data = cursor.fetchone()
                    
                    # Combine all data
                    results.append({
                        'score_data': score,
                        'band_data': band_data,
                        'qth_data': qth_data
                    })
                    
                    # Update last processed ID
                    self.last_processed_id = score_id
                
                return results
                    
        except sqlite3.Error as e:
            self.logger.error(f"Database error: {e}")
            return None
        except Exception as e:
            self.logger.error(f"Error fetching new records: {e}")
            return None

    def process_record(self, record):
        """Process a new contest record - override this in subclasses"""
        raise NotImplementedError("Subclasses must implement process_record")

    def run(self):
        """Main processing loop with improved polling"""
        self.logger.info(f"Starting data subscriber (polling every {self.polling_interval} seconds)...")
        
        while self.running:
            try:
                start_time = datetime.now()
                
                # Get new records
                records = self.get_new_records()
                
                if records:
                    self.logger.info(f"Found {len(records)} new records")
                    process_start = datetime.now()
                    
                    for record in records:
                        self.process_record(record)
                    
                    process_time = (datetime.now() - process_start).total_seconds()
                    self.logger.debug(f"Processed {len(records)} records in {process_time:.2f} seconds")
                
                # Calculate time until next check
                elapsed = (datetime.now() - start_time).total_seconds()
                wait_time = max(0, self.polling_interval - elapsed)
                
                if wait_time > 0:
                    if self.logger.isEnabledFor(logging.DEBUG):
                        self.logger.debug(f"Waiting {wait_time:.2f} seconds until next check")
                    time.sleep(wait_time)
                    
                # Log polling stats in debug mode
                if self.logger.isEnabledFor(logging.DEBUG):
                    total_time = (datetime.now() - self.last_check_time).total_seconds()
                    self.logger.debug(f"Poll cycle completed in {total_time:.2f} seconds")
                    self.last_check_time = datetime.now()
                
            except Exception as e:
                self.logger.error(f"Error in processing loop: {e}")
                self.logger.debug(traceback.format_exc())
                time.sleep(self.polling_interval)  # Wait before retry

    def cleanup(self):
        """Cleanup resources"""
        pass

class ContestMQTTPublisher(ContestDataSubscriber):
    def __init__(self, db_path, mqtt_config, debug=False, polling_interval=5):
        # Setup enhanced logging first
        self.setup_logging(debug)
        self.logger.debug("Initializing ContestMQTTPublisher")
        self.logger.debug(f"MQTT Config: {json.dumps(mqtt_config, indent=2)}")
        
        # Store MQTT config
        self.mqtt_config = mqtt_config
        
        # Initialize superclass with polling interval
        super().__init__(db_path, polling_interval)
        
        # Setup MQTT client
        self.setup_mqtt()
        
    def setup_logging(self, debug=False):
        """Configure detailed logging"""
        self.logger = logging.getLogger('ContestMQTTPublisher')
        self.logger.setLevel(logging.DEBUG if debug else logging.INFO)
        
        # Create formatters
        debug_formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
        )
        info_formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        )
        
        # Console handler
        console = logging.StreamHandler()
        console.setFormatter(debug_formatter if debug else info_formatter)
        self.logger.addHandler(console)
        
        # File handler for debug log
        if debug:
            debug_handler = logging.FileHandler('mqtt_publisher_debug.log')
            debug_handler.setFormatter(debug_formatter)
            debug_handler.setLevel(logging.DEBUG)
            self.logger.addHandler(debug_handler)

    def setup_mqtt(self):
        """Initialize MQTT client with detailed logging"""
        self.logger.debug("Setting up MQTT client")
        
        # Create MQTT client
        self.mqtt_client = mqtt.Client(client_id=self.mqtt_config.get('client_id'))
        
        # Enable MQTT client logging if in debug mode
        if self.logger.getEffectiveLevel() == logging.DEBUG:
            self.mqtt_client.enable_logger()  # Changed: removed self.logger argument
        
        # Set up callbacks with enhanced logging
        self.mqtt_client.on_connect = self.on_connect
        self.mqtt_client.on_disconnect = self.on_disconnect
        self.mqtt_client.on_publish = self.on_publish
        self.mqtt_client.on_log = self.on_mqtt_log
        
        # Configure authentication if provided
        if self.mqtt_config.get('username'):
            self.logger.debug("Configuring MQTT authentication")
            self.mqtt_client.username_pw_set(
                self.mqtt_config['username'],
                self.mqtt_config.get('password')
            )
        
        # Configure TLS if requested
        if self.mqtt_config.get('use_tls'):
            self.logger.debug("Configuring TLS for MQTT connection")
            self.mqtt_client.tls_set()
        
        try:
            self.logger.info(f"Connecting to MQTT broker at {self.mqtt_config['host']}:{self.mqtt_config['port']}")
            self.mqtt_client.connect(
                self.mqtt_config['host'],
                self.mqtt_config['port']
            )
            self.mqtt_client.loop_start()
            self.logger.info("MQTT client started successfully")
        except Exception as e:
            self.logger.error(f"Failed to connect to MQTT broker: {e}")
            self.logger.debug(traceback.format_exc())
            raise

    def on_connect(self, client, userdata, flags, rc):
        """Enhanced connection callback with debugging"""
        rc_codes = {
            0: "Connected successfully",
            1: "Connection refused - incorrect protocol version",
            2: "Connection refused - invalid client identifier",
            3: "Connection refused - server unavailable",
            4: "Connection refused - bad username or password",
            5: "Connection refused - not authorized"
        }
        
        if rc == 0:
            self.logger.info(f"Connected to MQTT broker at {self.mqtt_config['host']}:{self.mqtt_config['port']}")
            self.logger.debug(f"Connection flags: {flags}")
        else:
            self.logger.error(f"Connection failed: {rc_codes.get(rc, f'Unknown error ({rc})')}")

    def on_disconnect(self, client, userdata, rc):
        """Enhanced disconnection callback"""
        if rc == 0:
            self.logger.info("Cleanly disconnected from MQTT broker")
        else:
            self.logger.warning(f"Unexpectedly disconnected from MQTT broker with code: {rc}")
            self.logger.info("Attempting to reconnect...")
            try:
                self.mqtt_client.reconnect()
            except Exception as e:
                self.logger.error(f"Reconnection failed: {e}")
                self.logger.debug(traceback.format_exc())

    def on_publish(self, client, userdata, mid):
        """Callback for successful message publication"""
        self.logger.debug(f"Message {mid} published successfully")

    def on_mqtt_log(self, client, userdata, level, buf):
        """Callback for MQTT client logging"""
        self.logger.debug(f"MQTT Log: {buf}")

    def build_topic(self, record):
        """
        Build MQTT topic hierarchy from contest record.
        Format: contest/live/v1/{contest}/{callsign}
        """
        score_data = record['score_data']
        contest = score_data[2].replace(' ', '_')
        callsign = score_data[3]
        
        return f"contest/live/v1/{contest}/{callsign}"

    def get_contest_totals(self, contest, timestamp):
        """Get current contest totals including band breakdowns"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Get latest scores for all stations in this contest
                cursor.execute("""
                    WITH latest_scores AS (
                        SELECT cs.id, cs.callsign, cs.score, cs.qsos, cs.power,
                               cs.timestamp, cs.assisted, cs.transmitter
                        FROM contest_scores cs
                        WHERE cs.contest = ? 
                        AND cs.timestamp <= ?
                        AND (cs.callsign, cs.timestamp) IN (
                            SELECT cs2.callsign, MAX(cs2.timestamp)
                            FROM contest_scores cs2
                            WHERE cs2.contest = ?
                            AND cs2.timestamp <= ?
                            GROUP BY cs2.callsign
                        )
                    )
                    SELECT 
                        ls.callsign,
                        ls.score,
                        ls.qsos,
                        ls.power,
                        ls.assisted,
                        ls.transmitter,
                        ls.id,
                        ls.timestamp
                    FROM latest_scores ls
                    ORDER BY ls.score DESC
                """, (contest, timestamp, contest, timestamp))
                
                results = []
                for row in cursor.fetchall():
                    callsign, score, qsos, power, assisted, transmitter, score_id, ts = row
                    
                    # Get band breakdown
                    cursor.execute("""
                        SELECT bb.band, SUM(bb.qsos) as total_qsos
                        FROM contest_scores cs
                        JOIN band_breakdown bb ON bb.contest_score_id = cs.id
                        WHERE cs.callsign = ? 
                        AND cs.contest = ? 
                        AND cs.timestamp = ?
                        GROUP BY bb.band
                        ORDER BY bb.band
                    """, (callsign, contest, ts))
                    
                    band_qsos = {row[0]: row[1] for row in cursor.fetchall()}
                    
                    results.append({
                        'callsign': callsign,
                        'score': score,
                        'qsos': qsos,
                        'power': power,
                        'assisted': assisted,
                        'transmitter': transmitter,
                        'band_qsos': band_qsos
                    })
                
                self.logger.debug(f"Retrieved scores for {len(results)} stations in {contest}")
                return results
                
        except Exception as e:
            self.logger.error(f"Error getting contest totals: {e}")
            self.logger.debug(traceback.format_exc())
            return []

    def build_payload(self, record):
        """Build JSON payload with just the station's contest data"""
        try:
            score_data = record['score_data']
            qth_data = record['qth_data']
                
            # Build payload with just the essential station data
            payload = {
                "sq": score_data[0],
                "t": int(datetime.strptime(score_data[1], '%Y-%m-%d %H:%M:%S').timestamp()),
                "contest": score_data[2],
                "callsign": score_data[3],
                "score": score_data[4],
                "qsos": score_data[5],
                "mults": score_data[6],
                "power": score_data[7],
                "assisted": score_data[8],
                "tx": score_data[9],
                "bands": {},
            }
    
            # Add band breakdown if available
            if record['band_data']:
                for band_info in record['band_data']:
                    band_key = f"{band_info[0]}m"
                    payload["bands"][band_key] = {
                        "mode": band_info[1],
                        "qsos": band_info[2],
                        "points": band_info[3],
                        "mults": band_info[4]
                    }
    
            # Add QTH info if available
            if qth_data:
                payload["qth"] = {
                    "dxcc": qth_data[0],
                    "cqz": qth_data[1],
                    "ituz": qth_data[2],
                    "section": qth_data[3],
                    "state": qth_data[4],
                    "grid": qth_data[5]
                }
    
            return json.dumps(payload)
                
        except Exception as e:
            self.logger.error(f"Error building payload: {e}")
            self.logger.debug(traceback.format_exc())
            return None

    def process_record(self, record):
        """Process and publish contest record with enhanced logging"""
        try:
            self.logger.debug(f"Processing record: {json.dumps(record['score_data'])}")
            
            # Build topic and payload
            topic = self.build_topic(record)
            payload = self.build_payload(record)
            
            if payload:
                self.logger.debug(f"Publishing to topic: {topic}")
                self.logger.debug(f"Payload: {payload}")
                
                # Publish with QoS 1 and get message info
                info = self.mqtt_client.publish(topic, payload, qos=1)
                
                if info.rc == mqtt.MQTT_ERR_SUCCESS:
                    self.logger.debug(f"Message queued successfully with ID: {info.mid}")
                else:
                    self.logger.error(f"Failed to queue message, error code: {info.rc}")
                
        except Exception as e:
            self.logger.error(f"Error publishing record: {e}")
            self.logger.debug(traceback.format_exc())

    def cleanup(self):
        """Cleanup resources and stop MQTT client"""
        try:
            self.logger.info("Stopping MQTT client...")
            self.mqtt_client.loop_stop()
            self.mqtt_client.disconnect()
            self.logger.info("MQTT client stopped")
        except Exception as e:
            self.logger.error(f"Error during cleanup: {e}")
            self.logger.debug(traceback.format_exc())

def parse_arguments():
    """Parse and validate command line arguments"""
    parser = argparse.ArgumentParser(
        description='Contest Score MQTT Publisher',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  Basic usage:
    %(prog)s --db contest_data.db --host localhost

  With authentication:
    %(prog)s --db contest_data.db --host mqtt.example.com --username user --password pass

  With TLS:
    %(prog)s --db contest_data.db --host mqtt.example.com --tls
        """
    )
    
    parser.add_argument('--db', required=True,
                       help='Path to contest database')
    
    parser.add_argument('--host', required=True,
                       help='MQTT broker hostname')
    
    parser.add_argument('--port', type=int, default=1883,
                       help='MQTT broker port (default: 1883)')
    
    parser.add_argument('--username',
                       help='MQTT username')
    
    parser.add_argument('--password',
                       help='MQTT password')
    
    parser.add_argument('--client-id',
                       help='MQTT client ID (default: auto-generated)')
    
    parser.add_argument('--tls', action='store_true',
                       help='Use TLS for MQTT connection')
    
    parser.add_argument('--debug', action='store_true',
                       help='Enable debug logging')
    
    parser.add_argument('--poll-interval', type=int, default=5,
                       help='Database polling interval in seconds (default: 5)')

    return parser.parse_args()

def main():
    # Parse command line arguments
    args = parse_arguments()
    
    # Configure MQTT settings from arguments
    mqtt_config = {
        'host': args.host,
        'port': args.port,
        'username': args.username,
        'password': args.password,
        'client_id': args.client_id,
        'use_tls': args.tls
    }
    
    try:
        # Create publisher instance with polling interval
        publisher = ContestMQTTPublisher(
            db_path=args.db,
            mqtt_config=mqtt_config,
            debug=args.debug,
            polling_interval=args.poll_interval  # Pass the polling interval
        )
        
        # Log startup information
        if args.debug:
            publisher.logger.info("Contest Score MQTT Publisher starting up")
            publisher.logger.debug("Configuration:")
            publisher.logger.debug(f"  Database: {args.db}")
            publisher.logger.debug(f"  MQTT Host: {args.host}")
            publisher.logger.debug(f"  MQTT Port: {args.port}")
            publisher.logger.debug(f"  MQTT TLS: {args.tls}")
            publisher.logger.debug(f"  Polling Interval: {args.poll_interval} seconds")
            publisher.logger.debug(f"  Debug Mode: ON")
        
        # Run the publisher
        publisher.run()
        
    except KeyboardInterrupt:
        if publisher:
            publisher.logger.info("Shutting down...")
        else:
            logger.info("Shutting down...")
    except Exception as e:
        if publisher:
            publisher.logger.error(f"Fatal error: {e}")
            if args.debug:
                publisher.logger.debug(traceback.format_exc())
        else:
            logger.error(f"Fatal error during initialization: {e}")
            if args.debug:
                logger.debug(traceback.format_exc())
        sys.exit(1)
    finally:
        if publisher:
            publisher.cleanup()

if __name__ == "__main__":
    main()

===== optimize_db.py =====
import sqlite3
import time
import argparse

def optimize_database(db_path):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    try:
        print("Creating materialized view...")
        
        # Create the materialized table
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS latest_contest_scores AS
        WITH latest_scores AS (
            SELECT callsign, contest, MAX(timestamp) as max_ts
            FROM contest_scores
            GROUP BY callsign, contest
        )
        SELECT 
            cs.id,
            cs.callsign,
            cs.contest,
            cs.timestamp,
            cs.score,
            cs.power,
            cs.assisted,
            cs.qsos,
            cs.multipliers,
            qi.continent
        FROM contest_scores cs
        JOIN latest_scores ls 
            ON cs.callsign = ls.callsign 
            AND cs.contest = ls.contest
            AND cs.timestamp = ls.max_ts
        LEFT JOIN qth_info qi 
            ON qi.contest_score_id = cs.id
        """)

        # Create indexes
        print("Creating indexes...")
        cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_latest_contest_scores_contest 
        ON latest_contest_scores(contest)
        """)
        
        cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_latest_contest_scores_continent 
        ON latest_contest_scores(contest, continent)
        """)
        
        cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_latest_contest_scores_callsign 
        ON latest_contest_scores(callsign, contest)
        """)

        # Create update trigger
        print("Creating maintenance trigger...")
        cursor.execute("""
        CREATE TRIGGER IF NOT EXISTS update_latest_scores 
        AFTER INSERT ON contest_scores
        BEGIN
            DELETE FROM latest_contest_scores 
            WHERE callsign = NEW.callsign 
            AND contest = NEW.contest 
            AND timestamp < NEW.timestamp;
            
            INSERT INTO latest_contest_scores
            SELECT 
                NEW.id,
                NEW.callsign,
                NEW.contest,
                NEW.timestamp,
                NEW.score,
                NEW.power,
                NEW.assisted,
                NEW.qsos,
                NEW.multipliers,
                (SELECT continent FROM qth_info WHERE contest_score_id = NEW.id)
            WHERE NOT EXISTS (
                SELECT 1 FROM contest_scores 
                WHERE callsign = NEW.callsign 
                AND contest = NEW.contest 
                AND timestamp > NEW.timestamp
            );
        END
        """)

        # Test the performance
        def test_query(contest, callsign, continent):
            start_time = time.time()
            cursor.execute("""
                SELECT 
                    id, callsign, score, power, assisted, timestamp, qsos, multipliers,
                    CASE 
                        WHEN callsign = ? THEN 'current'
                        WHEN score > (SELECT score FROM latest_contest_scores 
                                    WHERE callsign = ? AND contest = ?) 
                        THEN 'above'
                        ELSE 'below'
                    END as position,
                    ROW_NUMBER() OVER (ORDER BY score DESC) as rn
                FROM latest_contest_scores
                WHERE contest = ? 
                AND continent = ?
                ORDER BY score DESC
            """, (callsign, callsign, contest, contest, continent))
            
            results = cursor.fetchall()
            end_time = time.time()
            return len(results), end_time - start_time

        # Test with ARRL-SS-SSB
        rows, duration = test_query("ARRL-SS-SSB", "AA3B", "NA")
        print(f"\nPerformance test results:")
        print(f"Rows returned: {rows}")
        print(f"Query duration: {duration:.3f} seconds")

        conn.commit()
        print("\nOptimization completed successfully!")
        
    except Exception as e:
        print(f"Error during optimization: {e}")
        conn.rollback()
    finally:
        conn.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Optimize contest database')
    parser.add_argument('--db', required=True, help='Database file path')
    args = parser.parse_args()
    optimize_database(args.db)

===== qso_diagnostics.py =====
# qso_diagnostics.py

import sqlite3
import argparse
import logging
import sys
from tabulate import tabulate
from datetime import datetime

class QsoDiagnostics:
    def __init__(self, db_path, log_path=None):
        self.db_path = db_path
        self.setup_logging(log_path)
        
    def setup_logging(self, log_path=None):
        """Configure logging to both file and console"""
        self.logger = logging.getLogger('QsoDiagnostics')
        self.logger.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        
        # Console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
        # File handler
        if log_path:
            file_handler = logging.FileHandler(log_path)
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)

    def check_duplicate_entries(self):
        """Check for duplicate entries in band_breakdown"""
        self.logger.info("Checking for duplicate band_breakdown entries...")
        
        query = """
        WITH duplicates AS (
            SELECT 
                cs.id,
                cs.callsign,
                cs.contest,
                bb.band,
                bb.mode,
                COUNT(*) as entry_count,
                SUM(bb.qsos) as total_qsos
            FROM contest_scores cs
            JOIN band_breakdown bb ON bb.contest_score_id = cs.id
            GROUP BY cs.id, cs.callsign, cs.contest, bb.band, bb.mode
            HAVING COUNT(*) > 1
        )
        SELECT * FROM duplicates
        ORDER BY entry_count DESC, callsign, contest
        """
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute(query)
                results = cursor.fetchall()
                
                if results:
                    self.logger.info(f"Found {len(results)} duplicate entries")
                    headers = ['ID', 'Callsign', 'Contest', 'Band', 'Mode', 'Entry Count', 'Total QSOs']
                    print("\nDuplicate Band/Mode Entries:")
                    print(tabulate(results, headers=headers, tablefmt='grid'))
                else:
                    self.logger.info("No duplicate band/mode entries found")
                    
        except Exception as e:
            self.logger.error(f"Error checking duplicates: {e}")

    def analyze_band_distribution(self):
        """Analyze QSO distribution across bands for inconsistent records"""
        self.logger.info("Analyzing QSO distribution across bands...")
        
        query = """
        WITH inconsistent_scores AS (
            SELECT cs.id, cs.callsign, cs.contest, cs.qsos as total_qsos,
                   (SELECT SUM(bb2.qsos) FROM band_breakdown bb2 
                    WHERE bb2.contest_score_id = cs.id) as band_total
            FROM contest_scores cs
            WHERE cs.qsos != (
                SELECT SUM(bb1.qsos) FROM band_breakdown bb1 
                WHERE bb1.contest_score_id = cs.id
            )
        )
        SELECT 
            is2.id,
            is2.callsign,
            is2.contest,
            is2.total_qsos,
            bb.band,
            bb.mode,
            bb.qsos as band_qsos,
            ROUND(CAST(bb.qsos AS FLOAT) / is2.total_qsos * 100, 2) as percentage
        FROM inconsistent_scores is2
        JOIN band_breakdown bb ON bb.contest_score_id = is2.id
        ORDER BY is2.id, bb.band
        """
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute(query)
                results = cursor.fetchall()
                
                if results:
                    headers = ['ID', 'Callsign', 'Contest', 'Total QSOs', 
                             'Band', 'Mode', 'Band QSOs', '% of Total']
                    print("\nBand Distribution for Inconsistent Records:")
                    print(tabulate(results, headers=headers, tablefmt='grid'))
                    
                    # Calculate statistics
                    contests = set((r[2] for r in results))
                    print(f"\nFound inconsistencies in {len(contests)} contests")
                    
        except Exception as e:
            self.logger.error(f"Error analyzing band distribution: {e}")

    def analyze_contest_patterns(self):
        """Look for patterns in specific contests"""
        self.logger.info("Analyzing contest-specific patterns...")
        
        query = """
        WITH contest_stats AS (
            SELECT 
                cs.contest,
                COUNT(DISTINCT cs.id) as total_entries,
                COUNT(DISTINCT CASE 
                    WHEN cs.qsos != (SELECT SUM(bb1.qsos) FROM band_breakdown bb1 
                                   WHERE bb1.contest_score_id = cs.id)
                    THEN cs.id 
                    END) as inconsistent_entries,
                AVG(CASE 
                    WHEN cs.qsos != (SELECT SUM(bb1.qsos) FROM band_breakdown bb1 
                                   WHERE bb1.contest_score_id = cs.id)
                    THEN CAST((SELECT SUM(bb1.qsos) FROM band_breakdown bb1 
                             WHERE bb1.contest_score_id = cs.id) AS FLOAT) / cs.qsos 
                    END) as avg_ratio
            FROM contest_scores cs
            GROUP BY cs.contest
            HAVING inconsistent_entries > 0
        )
        SELECT 
            contest,
            total_entries,
            inconsistent_entries,
            ROUND(CAST(inconsistent_entries AS FLOAT) / total_entries * 100, 2) as pct_inconsistent,
            ROUND(avg_ratio, 2) as avg_qso_ratio
        FROM contest_stats
        ORDER BY inconsistent_entries DESC
        """
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute(query)
                results = cursor.fetchall()
                
                if results:
                    headers = ['Contest', 'Total Entries', 'Inconsistent', '% Inconsistent', 'Avg QSO Ratio']
                    print("\nContest Pattern Analysis:")
                    print(tabulate(results, headers=headers, tablefmt='grid'))
                    
                    # Analyze patterns
                    high_ratio_contests = [r for r in results if r[4] >= 2.0]
                    if high_ratio_contests:
                        print("\nContests with QSO ratios >= 2.0 (possible double counting):")
                        print(tabulate(high_ratio_contests, headers=headers, tablefmt='grid'))
                        
        except Exception as e:
            self.logger.error(f"Error analyzing contest patterns: {e}")

    def check_logging_software(self):
        """Analyze if inconsistencies are related to specific logging software"""
        self.logger.info("Checking for logging software patterns...")
        
        # Note: This assumes there's some way to identify the logging software
        # You might need to modify this based on your actual data structure
        query = """
        WITH inconsistent_scores AS (
            SELECT cs.id, cs.callsign, cs.contest,
                   cs.qsos as total_qsos,
                   (SELECT SUM(bb.qsos) FROM band_breakdown bb 
                    WHERE bb.contest_score_id = cs.id) as band_total
            FROM contest_scores cs
            WHERE cs.qsos != (
                SELECT SUM(bb.qsos) FROM band_breakdown bb 
                WHERE bb.contest_score_id = cs.id
            )
        )
        SELECT DISTINCT
            cs.callsign,
            cs.contest,
            cs.timestamp,
            cs.qsos as reported_qsos,
            (SELECT SUM(bb.qsos) FROM band_breakdown bb 
             WHERE bb.contest_score_id = cs.id) as actual_qsos
        FROM inconsistent_scores is2
        JOIN contest_scores cs ON cs.id = is2.id
        ORDER BY cs.timestamp DESC
        """
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute(query)
                results = cursor.fetchall()
                
                if results:
                    headers = ['Callsign', 'Contest', 'Timestamp', 'Reported QSOs', 'Actual QSOs']
                    print("\nInconsistent Score Timeline:")
                    print(tabulate(results, headers=headers, tablefmt='grid'))
                    
                    # Analyze submission patterns
                    callsign_counts = {}
                    for r in results:
                        callsign_counts[r[0]] = callsign_counts.get(r[0], 0) + 1
                    
                    print("\nCallsigns with Multiple Inconsistencies:")
                    frequent_issues = [(call, count) for call, count in callsign_counts.items() 
                                     if count > 1]
                    if frequent_issues:
                        print(tabulate(frequent_issues, 
                                     headers=['Callsign', 'Issue Count'], 
                                     tablefmt='grid'))
                    
        except Exception as e:
            self.logger.error(f"Error checking logging software patterns: {e}")

def main():
    parser = argparse.ArgumentParser(
        description='Diagnose QSO count inconsistencies in contest database'
    )
    parser.add_argument('--db', required=True,
                      help='Database file path')
    parser.add_argument('--log',
                      help='Log file path')
    parser.add_argument('--all', action='store_true',
                      help='Run all diagnostics')
    parser.add_argument('--duplicates', action='store_true',
                      help='Check for duplicate band_breakdown entries')
    parser.add_argument('--bands', action='store_true',
                      help='Analyze QSO distribution across bands')
    parser.add_argument('--contests', action='store_true',
                      help='Analyze contest-specific patterns')
    parser.add_argument('--logging', action='store_true',
                      help='Check for logging software patterns')
    
    args = parser.parse_args()
    
    try:
        diagnostics = QsoDiagnostics(args.db, args.log)
        
        if args.all or args.duplicates:
            diagnostics.check_duplicate_entries()
        
        if args.all or args.bands:
            diagnostics.analyze_band_distribution()
            
        if args.all or args.contests:
            diagnostics.analyze_contest_patterns()
            
        if args.all or args.logging:
            diagnostics.check_logging_software()
            
    except Exception as e:
        print(f"Error running diagnostics: {e}")
        return 1
        
    return 0

if __name__ == "__main__":
    exit(main())

===== qso_rate.py =====
#!/usr/bin/env python3
import sqlite3
import logging
from datetime import datetime

class QsoRateCalculator:
    def __init__(self, db_path):
        self.db_path = db_path
        
    def calculate_rates(self, cursor, callsign, contest, current_ts, long_window=60, short_window=15):
        """Calculate QSO rates for both long and short time windows"""
        query = """
            WITH current_score AS (
                SELECT qsos, timestamp
                FROM contest_scores
                WHERE callsign = ? 
                AND contest = ?
                AND timestamp = ?
            ),
            long_window_score AS (
                SELECT qsos
                FROM contest_scores
                WHERE callsign = ?
                AND contest = ?
                AND timestamp <= datetime(?, '-60 minutes')
                ORDER BY ABS(JULIANDAY(timestamp) - JULIANDAY(datetime(?, '-60 minutes')))
                LIMIT 1
            ),
            short_window_score AS (
                SELECT qsos
                FROM contest_scores
                WHERE callsign = ?
                AND contest = ?
                AND timestamp <= datetime(?, '-15 minutes')
                ORDER BY ABS(JULIANDAY(timestamp) - JULIANDAY(datetime(?, '-15 minutes')))
                LIMIT 1
            )
            SELECT 
                cs.qsos as current_qsos,
                lws.qsos as long_window_qsos,
                sws.qsos as short_window_qsos
            FROM current_score cs
            LEFT JOIN long_window_score lws
            LEFT JOIN short_window_score sws
        """
        
        cursor.execute(query, (
            callsign, contest, current_ts,
            callsign, contest, current_ts, current_ts,
            callsign, contest, current_ts, current_ts
        ))
        
        result = cursor.fetchone()
        if not result:
            return 0, 0
            
        current_qsos, long_window_qsos, short_window_qsos = result
        
        # Calculate 60-minute rate
        long_rate = 0
        if long_window_qsos is not None:
            qso_diff = current_qsos - long_window_qsos
            if qso_diff > 0:
                long_rate = int(round((qso_diff * 60) / 60))  # 60-minute rate
                
        # Calculate 15-minute rate
        short_rate = 0
        if short_window_qsos is not None:
            qso_diff = current_qsos - short_window_qsos
            if qso_diff > 0:
                short_rate = int(round((qso_diff * 60) / 15))  # Convert 15-minute to hourly rate
                
        return long_rate, short_rate

    def calculate_band_rates(self, cursor, callsign, contest, current_ts, long_window=60, short_window=15):
        """Calculate per-band QSO rates for both time windows"""
        query = """
            WITH current_bands AS (
                SELECT 
                    bb.band,
                    bb.qsos as current_qsos,
                    bb.multipliers,
                    cs.timestamp as current_ts
                FROM contest_scores cs
                JOIN band_breakdown bb ON bb.contest_score_id = cs.id
                WHERE cs.callsign = ? 
                AND cs.contest = ?
                AND cs.timestamp = ?
            ),
            long_window_bands AS (
                SELECT 
                    bb.band,
                    bb.qsos as long_window_qsos
                FROM contest_scores cs
                JOIN band_breakdown bb ON bb.contest_score_id = cs.id
                WHERE cs.callsign = ?
                AND cs.contest = ?
                AND cs.timestamp <= ?
                AND cs.timestamp >= datetime(?, ? || ' minutes')
                ORDER BY cs.timestamp DESC
            ),
            short_window_bands AS (
                SELECT 
                    bb.band,
                    bb.qsos as short_window_qsos
                FROM contest_scores cs
                JOIN band_breakdown bb ON bb.contest_score_id = cs.id
                WHERE cs.callsign = ?
                AND cs.contest = ?
                AND cs.timestamp <= ?
                AND cs.timestamp >= datetime(?, ? || ' minutes')
                ORDER BY cs.timestamp DESC
            )
            SELECT 
                cb.band,
                cb.current_qsos,
                cb.multipliers,
                lwb.long_window_qsos,
                swb.short_window_qsos
            FROM current_bands cb
            LEFT JOIN long_window_bands lwb ON cb.band = lwb.band
            LEFT JOIN short_window_bands swb ON cb.band = swb.band
            WHERE cb.current_qsos > 0
            ORDER BY cb.band
        """
        
        cursor.execute(query, (
            callsign, contest, current_ts,
            callsign, contest, current_ts, current_ts, f"-{long_window}",
            callsign, contest, current_ts, current_ts, f"-{short_window}"
        ))
        
        results = cursor.fetchall()
        band_data = {}
        
        for row in results:
            band, current_qsos, multipliers, long_window_qsos, short_window_qsos = row
            
            # Calculate long window rate (60-minute)
            long_rate = 0
            if long_window_qsos is not None:
                qso_diff = current_qsos - long_window_qsos
                if qso_diff > 0:
                    long_rate = int(round((qso_diff * 60) / long_window))
            
            # Calculate short window rate (15-minute)
            short_rate = 0
            if short_window_qsos is not None:
                qso_diff = current_qsos - short_window_qsos
                if qso_diff > 0:
                    short_rate = int(round((qso_diff * 60) / short_window))
            
            band_data[band] = [current_qsos, multipliers, long_rate, short_rate]
        
        return band_data

===== query_analizer.py =====
import sqlite3
import time
from datetime import datetime
import argparse

def analyze_query_performance(db_path, contest, callsign, filter_type, filter_value):
    """Analyze query performance and execution plan"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    print("\n=== Breaking Down Query Performance ===")
    
    # Part 1: Analyze latest scores lookup
    print("\n1. Latest Scores Lookup Performance:")
    latest_scores_query = """
    SELECT callsign, MAX(timestamp) as max_ts
    FROM contest_scores
    WHERE contest = ?
    GROUP BY callsign
    """
    
    start_time = time.time()
    cursor.execute("EXPLAIN QUERY PLAN " + latest_scores_query, (contest,))
    plan = cursor.fetchall()
    print("\nExecution Plan:")
    for row in plan:
        print(f"id: {row[0]}, parent: {row[1]}, notused: {row[2]}, detail: {row[3]}")
    
    cursor.execute(latest_scores_query, (contest,))
    results = cursor.fetchall()
    time_taken = time.time() - start_time
    print(f"Time taken: {time_taken:.3f} seconds")
    print(f"Rows returned: {len(results)}")
    
    # Part 2: Analyze QTH info join performance
    print("\n2. QTH Info Join Performance:")
    qth_query = """
    SELECT COUNT(*), AVG(time_taken) 
    FROM (
        SELECT cs.id, cs.timestamp,
               (julianday(cs.timestamp) - julianday(cs2.timestamp)) * 86400 as time_taken
        FROM contest_scores cs
        LEFT JOIN qth_info qi ON qi.contest_score_id = cs.id
        LEFT JOIN contest_scores cs2 
            ON cs2.contest = cs.contest 
            AND cs2.callsign = cs.callsign 
            AND cs2.timestamp < cs.timestamp
        WHERE cs.contest = ?
        AND qi.continent = ?
        GROUP BY cs.id
    )
    """
    
    start_time = time.time()
    cursor.execute("EXPLAIN QUERY PLAN " + qth_query, (contest, filter_value))
    plan = cursor.fetchall()
    print("\nExecution Plan:")
    for row in plan:
        print(f"id: {row[0]}, parent: {row[1]}, notused: {row[2]}, detail: {row[3]}")
    
    cursor.execute(qth_query, (contest, filter_value))
    result = cursor.fetchone()
    time_taken = time.time() - start_time
    print(f"Time taken: {time_taken:.3f} seconds")
    if result[0]:
        print(f"Records found: {result[0]}")
        print(f"Average time between updates: {result[1]:.1f} seconds")
    
    # Analyze index usage statistics
    print("\n=== Index Usage Analysis ===")
    cursor.execute("ANALYZE")
    
    index_queries = [
        ("contest_scores by contest", 
         "SELECT * FROM contest_scores WHERE contest = ?", 
         (contest,)),
        ("qth_info by continent", 
         "SELECT * FROM qth_info WHERE continent = ?", 
         (filter_value,)),
        ("contest_scores by callsign and contest", 
         "SELECT * FROM contest_scores WHERE callsign = ? AND contest = ?", 
         (callsign, contest))
    ]
    
    for description, query, params in index_queries:
        print(f"\nAnalyzing {description}:")
        cursor.execute("EXPLAIN QUERY PLAN " + query, params)
        plan = cursor.fetchall()
        for row in plan:
            print(f"Using index: {row[3]}")
    
    # Check index sizes
    print("\n=== Index Size Analysis ===")
    cursor.execute("""
        SELECT name, 
               (SELECT COUNT(*) FROM contest_scores) as total_rows,
               (SELECT COUNT(DISTINCT contest) FROM contest_scores) as unique_contests,
               (SELECT COUNT(DISTINCT callsign) FROM contest_scores) as unique_calls
        FROM sqlite_master 
        WHERE type='index' 
        AND tbl_name='contest_scores'
    """)
    indexes = cursor.fetchall()
    for idx in indexes:
        print(f"\nIndex: {idx[0]}")
        print(f"Total rows indexed: {idx[1]:,}")
        print(f"Unique contests: {idx[2]:,}")
        print(f"Unique callsigns: {idx[3]:,}")
    
    # Analyze data distribution
    print("\n=== Data Distribution Analysis ===")
    cursor.execute("""
        SELECT COUNT(*) as record_count,
               COUNT(DISTINCT callsign) as unique_calls,
               COUNT(DISTINCT timestamp) as unique_timestamps,
               MIN(timestamp) as first_record,
               MAX(timestamp) as last_record
        FROM contest_scores 
        WHERE contest = ?
    """, (contest,))
    
    stats = cursor.fetchone()
    print(f"\nContest: {contest}")
    print(f"Total records: {stats[0]:,}")
    print(f"Unique callsigns: {stats[1]:,}")
    print(f"Unique timestamps: {stats[2]:,}")
    print(f"Time span: {stats[3]} to {stats[4]}")
    
    # Check for potential optimizations
    print("\n=== Optimization Suggestions ===")
    
    # Check if we need a compound index for the filtering
    cursor.execute("""
        SELECT COUNT(*) 
        FROM contest_scores cs
        JOIN qth_info qi ON qi.contest_score_id = cs.id
        WHERE cs.contest = ? AND qi.continent = ?
    """, (contest, filter_value))
    filtered_count = cursor.fetchone()[0]
    
    if filtered_count > 1000:
        print("\nSuggested optimizations:")
        print("1. Consider adding compound index:")
        print("   CREATE INDEX idx_opt_contest_continent ON contest_scores(contest), qth_info(continent)")
    
    # Check for data sparsity
    cursor.execute("""
        SELECT COUNT(*) * 100.0 / (
            SELECT COUNT(*) FROM contest_scores WHERE contest = ?
        ) as coverage
        FROM contest_scores cs
        JOIN qth_info qi ON qi.contest_score_id = cs.id
        WHERE cs.contest = ?
    """, (contest, contest))
    
    coverage = cursor.fetchone()[0]
    if coverage < 90:
        print("\n2. Data coverage warning:")
        print(f"   Only {coverage:.1f}% of contest records have QTH info")
        print("   Consider updating missing QTH data")
    
    conn.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Analyze SQLite query performance')
    parser.add_argument('--db', required=True, help='Database file path')
    parser.add_argument('--contest', required=True, help='Contest name')
    parser.add_argument('--callsign', required=True, help='Callsign')
    parser.add_argument('--filter-type', required=True, help='Filter type')
    parser.add_argument('--filter-value', required=True, help='Filter value')
    
    args = parser.parse_args()
    analyze_query_performance(
        args.db,
        args.contest,
        args.callsign,
        args.filter_type,
        args.filter_value
    )
  

===== rate_calculator.py =====
#!/usr/bin/env python3
import argparse
from datetime import datetime, timedelta
import sqlite3
import logging
import sys
import traceback

class RateCalculator:
    def __init__(self, db_path, debug=False):
        self.db_path = db_path
        self.debug = debug
        self.setup_logging()

    def setup_logging(self):
        """Setup logging configuration"""
        self.logger = logging.getLogger('RateCalculator')
        if not self.logger.handlers:
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s'
            )
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
            #self.logger.setLevel(logging.DEBUG if self.debug else logging.INFO)
            self.logger.setLevel(logging.ERROR) 

    def calculate_total_rate(self, cursor, callsign, contest, lookback_minutes=60):
        """Calculate total QSO rate using current UTC time as reference"""
        try:
            current_utc = datetime.utcnow()
            lookback_time = current_utc - timedelta(minutes=lookback_minutes)
            
            if self.debug:
                self.logger.debug(f"\nCalculating total rate for {callsign} in {contest}")
                self.logger.debug(f"Current UTC: {current_utc}")
                self.logger.debug(f"Looking back to: {lookback_time}")
            
            query = """
                WITH current_score AS (
                    SELECT 
                        cs.qsos as current_qsos,
                        cs.timestamp as current_ts
                    FROM contest_scores cs
                    WHERE cs.callsign = ?
                    AND cs.contest = ?
                    AND cs.timestamp <= ?
                    ORDER BY cs.timestamp DESC
                    LIMIT 1
                ),
                previous_score AS (
                    SELECT 
                        cs.qsos as prev_qsos,
                        cs.timestamp as prev_ts
                    FROM contest_scores cs
                    WHERE cs.callsign = ?
                    AND cs.contest = ?
                    AND cs.timestamp <= ?
                    ORDER BY ABS(JULIANDAY(cs.timestamp) - JULIANDAY(?))
                    LIMIT 1
                )
                SELECT 
                    current_qsos,
                    prev_qsos,
                    current_ts,
                    prev_ts
                FROM current_score, previous_score
            """
            
            cursor.execute(query, (
                callsign, contest, current_utc.strftime('%Y-%m-%d %H:%M:%S'),
                callsign, contest, lookback_time.strftime('%Y-%m-%d %H:%M:%S'),
                lookback_time.strftime('%Y-%m-%d %H:%M:%S')
            ))
            
            result = cursor.fetchone()
            if not result or None in result:
                if self.debug:
                    self.logger.debug("No data available for rate calculation")
                return 0
            
            current_qsos, prev_qsos, current_ts, prev_ts = result
            
            if self.debug:
                self.logger.debug("\nTotal rate analysis:")
                self.logger.debug(f"  Current QSOs: {current_qsos}")
                self.logger.debug(f"  Previous QSOs: {prev_qsos}")
                self.logger.debug(f"  Current timestamp: {current_ts}")
                self.logger.debug(f"  Previous timestamp: {prev_ts}")
            
            # Convert timestamps to datetime objects
            current_dt = datetime.strptime(current_ts, '%Y-%m-%d %H:%M:%S')
            prev_dt = datetime.strptime(prev_ts, '%Y-%m-%d %H:%M:%S')
            
            # Calculate time difference in minutes
            time_diff = (current_dt - prev_dt).total_seconds() / 60
            
            if self.debug:
                self.logger.debug(f"  Time difference: {time_diff:.1f} minutes")
            
            if time_diff <= 0:
                if self.debug:
                    self.logger.debug("Rate calculation skipped - invalid time difference")
                return 0
            
            qso_diff = current_qsos - prev_qsos
            
            if qso_diff == 0:
                if self.debug:
                    self.logger.debug("Rate is 0 - no new QSOs")
                return 0
            
            rate = int(round((qso_diff * 60) / time_diff))
            
            if self.debug:
                self.logger.debug(f"  QSO difference: {qso_diff}")
                self.logger.debug(f"  Calculated rate: {rate}/hr")
                
            return rate
            
        except Exception as e:
            self.logger.error(f"Error calculating total rate: {e}")
            self.logger.debug(traceback.format_exc())
            return 0

    def calculate_band_rates(self, cursor, callsign, contest, lookback_minutes=60):
        """Calculate per-band QSO rates"""
        try:
            current_utc = datetime.utcnow()
            lookback_time = current_utc - timedelta(minutes=lookback_minutes)
            
            if self.debug:
                self.logger.debug(f"\nCalculating band rates for {callsign} in {contest}")
                self.logger.debug(f"Current UTC: {current_utc}")
                self.logger.debug(f"Looking back to: {lookback_time}")
            
            query = """
                WITH current_bands AS (
                    SELECT 
                        bb.band,
                        bb.qsos as current_qsos,
                        cs.timestamp as current_ts
                    FROM contest_scores cs
                    JOIN band_breakdown bb ON bb.contest_score_id = cs.id
                    WHERE cs.callsign = ? 
                    AND cs.contest = ?
                    AND cs.timestamp <= ?
                    ORDER BY cs.timestamp DESC
                    LIMIT 1
                ),
                previous_bands AS (
                    SELECT 
                        bb.band,
                        bb.qsos as prev_qsos,
                        cs.timestamp as prev_ts
                    FROM contest_scores cs
                    JOIN band_breakdown bb ON bb.contest_score_id = cs.id
                    WHERE cs.callsign = ?
                    AND cs.contest = ?
                    AND cs.timestamp <= ?
                    ORDER BY ABS(JULIANDAY(cs.timestamp) - JULIANDAY(?))
                    LIMIT 1
                )
                SELECT 
                    cb.band,
                    cb.current_qsos,
                    pb.prev_qsos,
                    cb.current_ts,
                    pb.prev_ts
                FROM current_bands cb
                LEFT JOIN previous_bands pb ON cb.band = pb.band
                WHERE cb.current_qsos > 0
                ORDER BY cb.band
            """
            
            cursor.execute(query, (
                callsign, contest, current_utc.strftime('%Y-%m-%d %H:%M:%S'),
                callsign, contest, lookback_time.strftime('%Y-%m-%d %H:%M:%S'),
                lookback_time.strftime('%Y-%m-%d %H:%M:%S')
            ))
            
            results = cursor.fetchall()
            band_rates = {}
            
            if self.debug:
                self.logger.debug(f"Found {len(results)} bands with activity")
            
            for row in results:
                band, current_qsos, prev_qsos, current_ts, prev_ts = row
                
                if self.debug:
                    self.logger.debug(f"\nBand {band} analysis:")
                    self.logger.debug(f"  Current QSOs: {current_qsos}")
                    self.logger.debug(f"  Previous QSOs: {prev_qsos if prev_qsos else 0}")
                    self.logger.debug(f"  Current timestamp: {current_ts}")
                    self.logger.debug(f"  Previous timestamp: {prev_ts}")
                
                if not prev_ts:
                    if self.debug:
                        self.logger.debug("  Rate calculation skipped - no previous data")
                    band_rates[band] = 0
                    continue
                
                # Convert timestamps to datetime objects
                current_dt = datetime.strptime(current_ts, '%Y-%m-%d %H:%M:%S')
                prev_dt = datetime.strptime(prev_ts, '%Y-%m-%d %H:%M:%S')
                
                # Calculate time difference in minutes
                time_diff = (current_dt - prev_dt).total_seconds() / 60
                
                if self.debug:
                    self.logger.debug(f"  Time difference: {time_diff:.1f} minutes")
                
                if time_diff <= 0:
                    if self.debug:
                        self.logger.debug("  Rate calculation skipped - invalid time difference")
                    band_rates[band] = 0
                    continue
                
                # If previous QSOs is NULL, treat as 0
                prev_qsos = prev_qsos or 0
                qso_diff = current_qsos - prev_qsos
                
                if qso_diff == 0:
                    if self.debug:
                        self.logger.debug("  Rate is 0 - no new QSOs")
                    band_rates[band] = 0
                else:
                    rate = int(round((qso_diff * 60) / time_diff))
                    band_rates[band] = rate
                    if self.debug:
                        self.logger.debug(f"  QSO difference: {qso_diff}")
                        self.logger.debug(f"  Calculated rate: {rate}/hr")
            
            return band_rates
            
        except Exception as e:
            self.logger.error(f"Error calculating band rates: {e}")
            self.logger.debug(traceback.format_exc())
            return {}

def analyze_rates(args):
    """Analyze rates for given callsign and contest"""
    calculator = RateCalculator(args.db, args.debug)
    
    try:
        with sqlite3.connect(args.db) as conn:
            cursor = conn.cursor()
            
            # Calculate and display total rate
            total_rate = calculator.calculate_total_rate(cursor, args.call, args.contest, args.minutes)
            print(f"\nTotal QSO Rate: {total_rate}/hr")
            
            # Calculate and display band rates
            band_rates = calculator.calculate_band_rates(cursor, args.call, args.contest, args.minutes)
            if band_rates:
                print("\nPer-band QSO Rates:")
                for band in sorted(band_rates.keys()):
                    print(f"  {band}m: {band_rates[band]}/hr")
            else:
                print("\nNo band-specific data available")
                
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        if args.debug:
            print(traceback.format_exc(), file=sys.stderr)
        sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description='Calculate contest QSO rates')
    parser.add_argument('--db', default='contest_data.db',
                       help='Database file path (default: contest_data.db)')
    parser.add_argument('--call', required=True,
                       help='Callsign to analyze')
    parser.add_argument('--contest', required=True,
                       help='Contest name')
    parser.add_argument('--minutes', type=int, default=60,
                       help='Minutes to look back for rate calculation (default: 60)')
    parser.add_argument('--debug', action='store_true',
                       help='Enable debug output')
    
    args = parser.parse_args()
    analyze_rates(args)

if __name__ == "__main__":
    main()

===== score_reporter.py =====
#!/usr/bin/env python3
import sqlite3
import os
import logging
import traceback
from datetime import datetime, timedelta
from flask import request
import sys
from sql_queries import (CALCULATE_RATES, CALCULATE_BAND_RATES, GET_STATION_DETAILS,
                        GET_BAND_BREAKDOWN, GET_BAND_BREAKDOWN_WITH_RATES,
                        GET_FILTERS, INSERT_CONTEST_DATA, INSERT_BAND_BREAKDOWN,
                        INSERT_QTH_INFO)

class RateCalculator:
    def __init__(self, db_path, debug=False):
        self.db_path = db_path
        self.debug = debug
        self.setup_logging()

    def setup_logging(self):
        """Setup logging configuration"""
        self.logger = logging.getLogger('RateCalculator')
        if not self.logger.handlers:
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s'
            )
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
            self.logger.setLevel(logging.DEBUG if self.debug else logging.INFO)

    def calculate_rates(self, cursor, callsign, contest, timestamp, long_window=60, short_window=15):
        """Calculate QSO rates using centralized SQL query"""
        try:
            current_ts = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')
            
            # Calculate long window rate
            long_window_start = current_ts - timedelta(minutes=long_window)
            cursor.execute(CALCULATE_RATES, (callsign, contest, 
                           long_window_start.strftime('%Y-%m-%d %H:%M:%S'),
                           current_ts.strftime('%Y-%m-%d %H:%M:%S'),
                           long_window_start.strftime('%Y-%m-%d %H:%M:%S')))
            row = cursor.fetchone()
            long_rate = int(round(row[0] * 60 / long_window)) if row and row[0] else 0
    
            # Calculate short window rate
            short_window_start = current_ts - timedelta(minutes=short_window) 
            cursor.execute(CALCULATE_RATES, (callsign, contest,
                           short_window_start.strftime('%Y-%m-%d %H:%M:%S'),
                           current_ts.strftime('%Y-%m-%d %H:%M:%S'),
                           short_window_start.strftime('%Y-%m-%d %H:%M:%S')))
            row = cursor.fetchone()
            short_rate = int(round(row[0] * 60 / short_window)) if row and row[0] else 0
    
            return long_rate, short_rate
                
        except Exception as e:
            self.logger.error(f"Error calculating rates: {e}")
            self.logger.debug(traceback.format_exc())
            return 0, 0
    
    def calculate_band_rates(self, cursor, callsign, contest, timestamp, long_window=60, short_window=15):
        """Calculate per-band QSO rates using centralized SQL query"""
        try:
            current_ts = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')
            
            # Get current band data
            cursor.execute(GET_BAND_BREAKDOWN, (callsign, contest, timestamp))
            band_data = {row[0]: [row[1], row[2], 0, 0] for row in cursor.fetchall()}
    
            # Calculate long window rates
            long_window_start = current_ts - timedelta(minutes=long_window)
            cursor.execute(CALCULATE_BAND_RATES, (callsign, contest, 
                           long_window_start.strftime('%Y-%m-%d %H:%M:%S'),
                           current_ts.strftime('%Y-%m-%d %H:%M:%S'),
                           long_window_start.strftime('%Y-%m-%d %H:%M:%S')))
            for row in cursor.fetchall():
                band = row[0]
                if band in band_data:
                    band_data[band][2] = int(round(row[1] * 60 / long_window))
            
            # Calculate short window rates
            short_window_start = current_ts - timedelta(minutes=short_window)
            cursor.execute(CALCULATE_BAND_RATES, (callsign, contest,
                           short_window_start.strftime('%Y-%m-%d %H:%M:%S'),
                           current_ts.strftime('%Y-%m-%d %H:%M:%S'),
                           short_window_start.strftime('%Y-%m-%d %H:%M:%S')))
            for row in cursor.fetchall():
                band = row[0]
                if band in band_data:
                    band_data[band][3] = int(round(row[1] * 60 / short_window))
            
            return band_data
                
        except Exception as e:
            self.logger.error(f"Error calculating band rates: {e}")
            self.logger.debug(traceback.format_exc())
            return {}

class ScoreReporter:
    def __init__(self, db_path=None, template_path=None, rate_minutes=60):
        """Initialize the ScoreReporter class"""
        self.db_path = db_path or 'contest_data.db'
        self.template_path = template_path or 'templates/score_template.html'
        self.rate_calculator = RateCalculator(self.db_path)
        self.setup_logging()

    def setup_logging(self):
        """Setup logging configuration with both file and console handlers"""
        try:
            # Create logger
            self.logger = logging.getLogger('ScoreReporter')
            self.logger.setLevel(logging.DEBUG)
            
            # Clear any existing handlers
            if self.logger.handlers:
                self.logger.handlers.clear()
            
            # Create logs directory if it doesn't exist
            log_dir = '/opt/livescore/logs'
            os.makedirs(log_dir, exist_ok=True)
            
            # Create formatters
            detailed_formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
            )
            console_formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s'
            )
            
            # File handler for detailed debugging
            debug_log = os.path.join(log_dir, 'score_reporter.log')
            file_handler = logging.FileHandler(debug_log)
            file_handler.setLevel(logging.DEBUG)
            file_handler.setFormatter(detailed_formatter)
            
            # Console handler for basic info
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setLevel(logging.INFO)
            console_handler.setFormatter(console_formatter)
            
            # Add handlers to logger
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
            
        except Exception as e:
            print(f"Error setting up logging: {e}", file=sys.stderr)
            print(traceback.format_exc(), file=sys.stderr)
            raise
        
    def get_station_details(self, callsign, contest, filter_type=None, filter_value=None):
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Get base query results
                base_query = GET_STATION_DETAILS
                params = [contest, contest]
                
                # Add QTH filter if specified
                if filter_type and filter_value and filter_type.lower() != 'none':
                    filter_map = {
                        'DXCC': 'dxcc_country',
                        'CQ Zone': 'cq_zone',
                        'IARU Zone': 'iaru_zone',
                        'ARRL Section': 'arrl_section',
                        'State/Province': 'state_province',
                        'Continent': 'continent'
                    }
                    
                    if field := filter_map.get(filter_type):
                        base_query = base_query.replace(
                            "WHERE cs.contest = ?",
                            f"WHERE cs.contest = ? AND qi.{field} = ?"
                        )
                        params.append(filter_value)
    
                # Handle position filter
                position_filter = request.args.get('position_filter', 'all')
                if position_filter == 'range':
                    params.extend([callsign, callsign, callsign])
                else:
                    params.extend([callsign, callsign, callsign])  # Add third callsign param for consistency

                cursor.execute(base_query, params)
                return cursor.fetchall()
    
        except Exception as e:
            self.logger.error(f"Error in get_station_details: {e}")
            self.logger.error(traceback.format_exc())
            return None

    def get_band_breakdown_with_rates(self, station_id, callsign, contest, timestamp):
        """Get band breakdown with both 60-minute and 15-minute rates"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                params = (
                    callsign, contest, timestamp,                  # current_score parameters (3)
                    callsign, contest, timestamp, timestamp,       # long_window_score parameters (4)
                    callsign, contest, timestamp, timestamp        # short_window_score parameters (4)
                )
                
                cursor.execute(GET_BAND_BREAKDOWN_WITH_RATES, params)
                results = cursor.fetchall()
                band_data = {}
                
                for row in results:
                    band, current_qsos, multipliers, long_window_qsos, short_window_qsos = row
                    
                    # Calculate 60-minute rate
                    long_rate = 0
                    if long_window_qsos is not None:
                        qso_diff = current_qsos - long_window_qsos
                        if qso_diff > 0:
                            long_rate = int(round((qso_diff * 60) / 60))  # 60-minute rate
                    
                    # Calculate 15-minute rate
                    short_rate = 0
                    if short_window_qsos is not None:
                        qso_diff = current_qsos - short_window_qsos
                        if qso_diff > 0:
                            short_rate = int(round((qso_diff * 60) / 15))  # Convert 15-minute to hourly rate
                    
                    band_data[band] = [current_qsos, multipliers, long_rate, short_rate]
                
                return band_data
                        
        except Exception as e:
            self.logger.error(f"Error in get_band_breakdown_with_rates: {e}")
            self.logger.error(traceback.format_exc())
            return {}

    def get_total_rates(self, station_id, callsign, contest, timestamp):
        """Get total QSO rates for both time windows"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                return self.rate_calculator.calculate_rates(
                    cursor, callsign, contest, timestamp
                )
        except Exception as e:
            self.logger.error(f"Error in get_total_rates: {e}")
            self.logger.error(traceback.format_exc())
            return 0, 0

    def generate_html_content(self, template, callsign, contest, stations):
        """Generate HTML content from template and data"""
        try:
            from html import escape
            import re
            
            # Escape all data values
            safe_callsign = escape(callsign)
            safe_contest = escape(contest)
            
            # Prepare station data
            station_rows = []
            for station in stations:
                safe_station = [escape(str(x)) if x is not None else '' for x in station]
                station_rows.append(safe_station)
            
            # Create template variables
            template_vars = {
                'callsign': safe_callsign,
                'contest': safe_contest,
                'stations': station_rows,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'table_rows': ''.join(f'<tr>{"".join(f"<td>{cell}</td>" for cell in row)}</tr>' for row in station_rows),
                'filter_info_div': '<div class="filter-info">No filters applied</div>',
                'additional_css': '',
                'power': 'High',
                'assisted': 'Assisted'
            }
            
            # Perform template substitution for both {var} and {{var}} syntax
            def replace_var(match):
                var_name = match.group(1)
                return str(template_vars.get(var_name, ''))
            
            # First replace {variable} patterns (Python template variables)
            html_content = re.sub(r'\{(\w+)\}', replace_var, template)
            # Then replace {{variable}} patterns (JavaScript template literals)
            # Only replace if they're not inside <script> tags
            def js_replace(match):
                if match.group(0).startswith('{{') and '</script>' not in match.string[:match.start()]:
                    return str(template_vars.get(match.group(1), ''))
                return match.group(0)
            
            html_content = re.sub(r'\{\{(\w+)\}\}', js_replace, html_content)
            
            return html_content
            
        except Exception as e:
            self.logger.error(f"Error generating HTML content: {e}")
            self.logger.error(traceback.format_exc())
            return "<h1>Error generating report</h1>"

    # ... (rest of the ScoreReporter class remains unchanged)

===== sql_queries.py =====
# SQL Queries for LiveScore Contest Reporting System

# Contest queries
GET_CONTESTS = """
    SELECT contest, COUNT(DISTINCT callsign) AS active_stations
    FROM contest_scores
    GROUP BY contest
    ORDER BY contest
"""

GET_CALLSIGNS = """
    WITH latest_scores AS (
        SELECT cs.callsign, cs.qsos, cs.timestamp
        FROM contest_scores cs
        INNER JOIN (
            SELECT callsign, MAX(timestamp) as max_ts
            FROM contest_scores
            WHERE contest = ?
            GROUP BY callsign
        ) latest ON cs.callsign = latest.callsign 
            AND cs.timestamp = latest.max_ts
        WHERE cs.contest = ?
        AND cs.qsos > 0
    )
    SELECT DISTINCT callsign, qsos as qso_count
    FROM latest_scores
    ORDER BY callsign
"""

API_GET_CALLSIGNS = """
    SELECT DISTINCT callsign
    FROM contest_scores
    WHERE contest = ?
    AND qsos > 0
    ORDER BY callsign
"""

VERIFY_STATION = """
    SELECT COUNT(*) 
    FROM contest_scores
    WHERE contest = ?
    AND callsign = ?
"""

GET_FILTERS = """
    SELECT qi.dxcc_country, qi.cq_zone, qi.iaru_zone, 
           qi.arrl_section, qi.state_province, qi.continent
    FROM contest_scores cs
    JOIN qth_info qi ON qi.contest_score_id = cs.id
    WHERE cs.contest = ? AND cs.callsign = ?
    ORDER BY cs.timestamp DESC
    LIMIT 1
"""

# Rate calculation queries
CALCULATE_RATES = """
    WITH now AS (
        SELECT datetime('now') as current_utc
    ),
    total_qsos AS (
        SELECT cs.timestamp, SUM(bb.qsos) as total
        FROM contest_scores cs
        JOIN band_breakdown bb ON bb.contest_score_id = cs.id
        CROSS JOIN now n 
        WHERE cs.callsign = ? 
        AND cs.contest = ?
        AND cs.timestamp >= ?
        AND cs.timestamp <= ?
        AND (julianday(n.current_utc) - julianday(cs.timestamp)) * 24 * 60 <= 75
        GROUP BY cs.timestamp
        ORDER BY cs.timestamp DESC
    )
    SELECT 
        MAX(total) - MIN(total) as qso_diff,
        COUNT(*) as samples,
        MAX(timestamp) as latest,
        MIN(timestamp) as earliest
    FROM total_qsos
    WHERE timestamp >= ?
"""

CALCULATE_BAND_RATES = """
    WITH now AS (
        SELECT datetime('now') as current_utc
    ),
    band_qsos AS (
        SELECT cs.timestamp, bb.band, bb.qsos
        FROM contest_scores cs
        JOIN band_breakdown bb ON bb.contest_score_id = cs.id
        CROSS JOIN now n
        WHERE cs.callsign = ? 
        AND cs.contest = ?
        AND cs.timestamp >= ?
        AND cs.timestamp <= ?
        AND (julianday(n.current_utc) - julianday(cs.timestamp)) * 24 * 60 <= 75
        ORDER BY cs.timestamp DESC
    )
    SELECT 
        band,
        MAX(qsos) - MIN(qsos) as qso_diff,
        COUNT(*) as samples,
        MAX(timestamp) as latest,
        MIN(timestamp) as earliest
    FROM band_qsos
    WHERE timestamp >= ?
    GROUP BY band
    HAVING qso_diff > 0
"""

# Station details query
GET_STATION_DETAILS = """
    WITH ranked_stations AS (
        SELECT 
            cs.id,
            cs.callsign,
            cs.score,
            cs.power,
            cs.assisted,
            cs.timestamp,
            cs.qsos,
            cs.multipliers,
            ROW_NUMBER() OVER (ORDER BY cs.score DESC) as position
        FROM contest_scores cs
        JOIN qth_info qi ON qi.contest_score_id = cs.id
        WHERE cs.contest = ?
        AND cs.id IN (
            SELECT MAX(id)
            FROM contest_scores
            WHERE contest = ?
            GROUP BY callsign
        )
    )
    SELECT rs.*, 
           CASE WHEN rs.callsign = ? THEN 'current'
                WHEN rs.score > (SELECT score FROM ranked_stations WHERE callsign = ?) 
                THEN 'above' ELSE 'below' END as rel_pos
    FROM ranked_stations rs
    WHERE EXISTS (
        SELECT 1 FROM ranked_stations ref 
        WHERE ref.callsign = ? 
        AND ABS(rs.position - ref.position) <= 5
    )
    ORDER BY rs.score DESC
"""

# Band breakdown queries
GET_BAND_BREAKDOWN = """
    SELECT bb.band, bb.qsos, bb.multipliers
    FROM contest_scores cs
    JOIN band_breakdown bb ON bb.contest_score_id = cs.id
    WHERE cs.callsign = ?
    AND cs.contest = ?
    AND cs.timestamp = ?
    AND bb.qsos > 0
    ORDER BY bb.band
"""

GET_BAND_BREAKDOWN_WITH_RATES = """
    WITH current_score AS (
        SELECT cs.id, cs.timestamp, bb.band, bb.qsos, bb.multipliers
        FROM contest_scores cs
        JOIN band_breakdown bb ON bb.contest_score_id = cs.id
        WHERE cs.callsign = ? 
        AND cs.contest = ?
        AND cs.timestamp = ?
    ),
    long_window_score AS (
        SELECT bb.band, bb.qsos
        FROM contest_scores cs
        JOIN band_breakdown bb ON bb.contest_score_id = cs.id
        WHERE cs.callsign = ?
        AND cs.contest = ?
        AND cs.timestamp <= datetime(?, '-60 minutes')
        AND cs.timestamp >= datetime(?, '-65 minutes')
        ORDER BY cs.timestamp DESC
    ),
    short_window_score AS (
        SELECT bb.band, bb.qsos
        FROM contest_scores cs
        JOIN band_breakdown bb ON bb.contest_score_id = cs.id
        WHERE cs.callsign = ?
        AND cs.contest = ?
        AND cs.timestamp <= datetime(?, '-15 minutes')
        AND cs.timestamp >= datetime(?, '-20 minutes')
        ORDER BY cs.timestamp DESC
    )
    SELECT 
        cs.band,
        cs.qsos as current_qsos,
        cs.multipliers,
        lws.qsos as long_window_qsos,
        sws.qsos as short_window_qsos
    FROM current_score cs
    LEFT JOIN long_window_score lws ON cs.band = lws.band
    LEFT JOIN short_window_score sws ON cs.band = sws.band
    WHERE cs.qsos > 0
    ORDER BY cs.band
"""

# Database schema queries
CREATE_CONTEST_SCORES_TABLE = """
    CREATE TABLE IF NOT EXISTS contest_scores (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        timestamp DATETIME,
        contest TEXT,
        callsign TEXT,
        power TEXT,
        assisted TEXT,
        transmitter TEXT,
        ops TEXT,
        bands TEXT,
        mode TEXT,
        overlay TEXT,
        club TEXT,
        section TEXT,
        score INTEGER,
        qsos INTEGER,
        multipliers INTEGER,
        points INTEGER
    )
"""

CREATE_BAND_BREAKDOWN_TABLE = """
    CREATE TABLE IF NOT EXISTS band_breakdown (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        contest_score_id INTEGER,
        band TEXT,
        mode TEXT,
        qsos INTEGER,
        points INTEGER,
        multipliers INTEGER,
        FOREIGN KEY (contest_score_id) REFERENCES contest_scores(id)
    )
"""

CREATE_QTH_INFO_TABLE = """
    CREATE TABLE IF NOT EXISTS qth_info (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        contest_score_id INTEGER,
        dxcc_country TEXT,
        cq_zone TEXT,
        iaru_zone TEXT,
        arrl_section TEXT,
        state_province TEXT,
        grid6 TEXT,
        FOREIGN KEY (contest_score_id) REFERENCES contest_scores(id)
    )
"""

# Data insertion queries
INSERT_QTH_INFO = """
    INSERT INTO qth_info (
        contest_score_id, dxcc_country, continent, cq_zone, 
        iaru_zone, arrl_section, state_province, grid6
    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
"""

INSERT_BAND_BREAKDOWN = """
    INSERT INTO band_breakdown (
        contest_score_id, band, mode, qsos, points, multipliers
    ) VALUES (?, ?, ?, ?, ?, ?)
"""

INSERT_CONTEST_DATA = """
    INSERT INTO contest_scores (
        timestamp, contest, callsign, power, assisted, transmitter,
        ops, bands, mode, overlay, club, section, score, qsos,
        multipliers, points
    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
"""

# Data consistency queries
CHECK_QSO_CONSISTENCY = """
    SELECT cs.id, cs.callsign, cs.qsos, SUM(bb.qsos) as total_band_qsos
    FROM contest_scores cs
    LEFT JOIN band_breakdown bb ON bb.contest_score_id = cs.id
    GROUP BY cs.id
    HAVING cs.qsos != total_band_qsos
    AND total_band_qsos IS NOT NULL
"""

COUNT_ORPHANED_BAND_BREAKDOWN = """
    SELECT COUNT(*) 
    FROM band_breakdown bb
    LEFT JOIN contest_scores cs ON cs.id = bb.contest_score_id
    WHERE cs.id IS NULL
"""

COUNT_ORPHANED_QTH_INFO = """
    SELECT COUNT(*) 
    FROM qth_info qi
    LEFT JOIN contest_scores cs ON cs.id = qi.contest_score_id
    WHERE cs.id IS NULL
"""

ANALYZE_ORPHANED_BAND_BREAKDOWN = """
    SELECT 
        bb.contest_score_id,
        COUNT(*) as record_count,
        SUM(bb.qsos) as total_qsos,
        GROUP_CONCAT(DISTINCT bb.band) as bands,
        MIN(bb.qsos) as min_qsos,
        MAX(bb.qsos) as max_qsos
    FROM band_breakdown bb
    LEFT JOIN contest_scores cs ON cs.id = bb.contest_score_id
    WHERE cs.id IS NULL
    GROUP BY bb.contest_score_id
    ORDER BY record_count DESC
    LIMIT 10
"""

ANALYZE_ORPHANED_QTH_INFO = """
    SELECT 
        qi.contest_score_id,
        qi.dxcc_country,
        qi.cq_zone,
        qi.iaru_zone,
        qi.arrl_section,
        qi.state_province
    FROM qth_info qi
    LEFT JOIN contest_scores cs ON cs.id = qi.contest_score_id
    WHERE cs.id IS NULL
    ORDER BY qi.contest_score_id DESC
    LIMIT 10
"""

DELETE_ORPHANED_BAND_BREAKDOWN = """
    DELETE FROM band_breakdown
    WHERE contest_score_id IN (
        SELECT bb.contest_score_id
        FROM band_breakdown bb
        LEFT JOIN contest_scores cs ON cs.id = bb.contest_score_id
        WHERE cs.id IS NULL
    )
"""

DELETE_ORPHANED_QTH_INFO = """
    DELETE FROM qth_info
    WHERE contest_score_id IN (
        SELECT qi.contest_score_id
        FROM qth_info qi
        LEFT JOIN contest_scores cs ON cs.id = qi.contest_score_id
        WHERE cs.id IS NULL
    )
"""

FIND_SMALL_CONTESTS = """
    SELECT contest, COUNT(DISTINCT callsign) as num_callsigns
    FROM contest_scores
    GROUP BY contest
    HAVING num_callsigns < 5
"""

GET_OLD_RECORDS = """
    SELECT id
    FROM contest_scores
    WHERE timestamp < ?
"""

GET_ARCHIVE_RECORDS = """
    SELECT id, contest, timestamp
    FROM contest_scores
    WHERE timestamp < ?
    ORDER BY timestamp DESC
"""

# Data deletion queries
DELETE_BAND_BREAKDOWN_BY_CONTEST_SCORE_ID = """
    DELETE FROM band_breakdown
    WHERE contest_score_id IN (
        SELECT id FROM contest_scores WHERE contest = ?
    )
"""

DELETE_QTH_INFO_BY_CONTEST_SCORE_ID = """
    DELETE FROM qth_info
    WHERE contest_score_id IN (
        SELECT id FROM contest_scores WHERE contest = ?
    )
"""

DELETE_CONTEST_SCORES_BY_CONTEST = """
    DELETE FROM contest_scores
    WHERE contest = ?
"""

===== view_data.py =====
#!/usr/bin/env python3
import argparse
import sqlite3
from contest_db_viewer import ContestDatabaseViewer
from display_utils import format_qth_statistics, format_qth_details
from tabulate import tabulate
import logging

def show_operating_categories(db_path, contest=None):
    """Display operating category statistics including all category fields"""
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # Base query for category statistics - now with properly qualified column names
            query = """
                WITH latest_scores AS (
                    SELECT cs.id, cs.callsign, cs.contest, cs.timestamp,
                           cs.power, cs.assisted, cs.transmitter, cs.ops, cs.bands, cs.mode,
                           cs.qsos, cs.score
                    FROM contest_scores cs
                    INNER JOIN (
                        SELECT callsign, contest, MAX(timestamp) as max_ts
                        FROM contest_scores
                        GROUP BY callsign, contest
                    ) latest ON cs.callsign = latest.callsign 
                        AND cs.contest = latest.contest
                        AND cs.timestamp = latest.max_ts
                    {where_clause}
                )
            """
            
            where_clause = "WHERE cs.contest = ?" if contest else ""
            base_query = query.format(where_clause=where_clause)
            params = (contest,) if contest else ()

            # Function to get category statistics with qualified column names
            def get_category_stats(category_field):
                category_query = base_query + f"""
                    SELECT 
                        ls.contest,
                        ls.{category_field},
                        COUNT(*) as count,
                        GROUP_CONCAT(ls.callsign) as stations,
                        SUM(ls.qsos) as total_qsos,
                        MAX(ls.score) as high_score,
                        MIN(ls.score) as low_score,
                        AVG(ls.score) as avg_score
                    FROM latest_scores ls
                    WHERE ls.{category_field} IS NOT NULL AND ls.{category_field} != ''
                    GROUP BY ls.contest, ls.{category_field}
                    ORDER BY ls.contest, ls.{category_field}
                """
                cursor.execute(category_query, params)
                return cursor.fetchall()

            # Get statistics for all categories
            categories = {
                'Power': get_category_stats('power'),
                'Assisted': get_category_stats('assisted'),
                'Transmitter': get_category_stats('transmitter'),
                'Operator': get_category_stats('ops'),
                'Bands': get_category_stats('bands'),
                'Mode': get_category_stats('mode')
            }
            
            # Display results
            contest_str = f" for {contest}" if contest else ""
            print(f"\n=== Operating Category Statistics{contest_str} ===\n")
            
            def format_category_stats(stats, category_name):
                if not stats:
                    return
                
                print(f"\n{category_name} Categories:")
                print("=" * (len(category_name) + 11))
                
                current_contest = None
                table_data = []
                headers = ['Category', 'Count', 'Total QSOs', 'Avg Score', 'High Score', 'Example Stations']
                
                for row in stats:
                    if not contest and current_contest != row[0]:
                        if table_data:
                            print(tabulate(table_data, headers=headers, 
                                        tablefmt='grid', floatfmt=".0f"))
                            table_data = []
                        current_contest = row[0]
                        print(f"\nContest: {current_contest}")
                    
                    # Format scores
                    avg_score = int(row[7]) if row[7] else 0
                    high_score = int(row[5]) if row[5] else 0
                    
                    # Format station list
                    stations = row[3].split(',')
                    station_str = ', '.join(stations[:3])
                    if len(stations) > 3:
                        station_str += f" (+{len(stations)-3})"
                    
                    category_value = row[1] or 'Unknown'
                    table_data.append([
                        category_value,
                        row[2],
                        row[4],
                        format(avg_score, ",d"),
                        format(high_score, ",d"),
                        station_str
                    ])
                
                if table_data:
                    print(tabulate(table_data, headers=headers, 
                                tablefmt='grid', floatfmt=".0f"))
            
            # Display statistics for each category type
            for category_name, stats in categories.items():
                format_category_stats(stats, category_name)
            
            # Get combined category breakdown with properly qualified column names
            if contest:
                print(f"\nDetailed Category Combinations for {contest}:")
                print("=" * 40)
                cursor.execute("""
                    WITH latest_scores AS (
                        SELECT cs.id, cs.callsign, cs.power, cs.assisted, 
                               cs.transmitter, cs.ops, cs.bands, cs.mode
                        FROM contest_scores cs
                        INNER JOIN (
                            SELECT callsign, MAX(timestamp) as max_ts
                            FROM contest_scores cs2
                            WHERE cs2.contest = ?
                            GROUP BY cs2.callsign
                        ) latest ON cs.callsign = latest.callsign 
                            AND cs.timestamp = latest.max_ts
                        WHERE cs.contest = ?
                    )
                    SELECT 
                        COALESCE(ls.power, 'Unknown') as power,
                        COALESCE(ls.assisted, 'Unknown') as assisted,
                        COALESCE(ls.transmitter, 'Unknown') as transmitter,
                        COALESCE(ls.ops, 'Unknown') as ops,
                        COALESCE(ls.bands, 'Unknown') as bands,
                        COALESCE(ls.mode, 'Unknown') as mode,
                        COUNT(*) as count,
                        GROUP_CONCAT(ls.callsign) as stations
                    FROM latest_scores ls
                    GROUP BY ls.power, ls.assisted, ls.transmitter, 
                             ls.ops, ls.bands, ls.mode
                    ORDER BY count DESC
                    LIMIT 10
                """, (contest, contest))
                
                combo_data = []
                for row in cursor.fetchall():
                    stations = row[7].split(',')
                    station_str = ', '.join(stations[:2])
                    if len(stations) > 2:
                        station_str += f" (+{len(stations)-2})"
                    
                    combo_data.append([
                        row[0], row[1], row[2], row[3], 
                        row[4], row[5], row[6], station_str
                    ])
                
                if combo_data:
                    print("\nTop Category Combinations:")
                    headers = ['Power', 'Assisted', 'Transmitter', 'Operator', 
                             'Bands', 'Mode', 'Count', 'Example Stations']
                    print(tabulate(combo_data, headers=headers, tablefmt='grid'))
            
    except sqlite3.Error as e:
        print(f"Database error: {e}")
        return False
    except Exception as e:
        print(f"Unexpected error: {e}")
        return False
    return True


def show_database_structure(db_path):
    """Display the database structure including tables, columns, and indexes"""
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # Get all tables
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' 
                ORDER BY name
            """)
            tables = cursor.fetchall()
            
            print("\n=== Database Structure ===\n")
            
            for table in tables:
                table_name = table[0]
                print(f"\nTable: {table_name}")
                print("-" * (len(table_name) + 7))
                
                # Get column information
                cursor.execute(f"PRAGMA table_info({table_name})")
                columns = cursor.fetchall()
                
                column_data = []
                for col in columns:
                    col_info = {
                        'Name': col[1],
                        'Type': col[2],
                        'NotNull': 'NOT NULL' if col[3] else '',
                        'DefaultValue': col[4] if col[4] is not None else '',
                        'PrimaryKey': 'PRIMARY KEY' if col[5] else ''
                    }
                    column_data.append(col_info)
                
                print(tabulate(
                    column_data, 
                    headers='keys',
                    tablefmt='grid'
                ))
                
                # Get foreign key information
                cursor.execute(f"PRAGMA foreign_key_list({table_name})")
                foreign_keys = cursor.fetchall()
                
                if foreign_keys:
                    print("\nForeign Keys:")
                    fk_data = []
                    for fk in foreign_keys:
                        fk_info = {
                            'Column': fk[3],
                            'References': f"{fk[2]}({fk[4]})",
                            'OnUpdate': fk[5],
                            'OnDelete': fk[6]
                        }
                        fk_data.append(fk_info)
                    print(tabulate(
                        fk_data,
                        headers='keys',
                        tablefmt='grid'
                    ))
                
                # Get index information
                cursor.execute(f"""
                    SELECT name, sql 
                    FROM sqlite_master 
                    WHERE type='index' 
                    AND tbl_name=?
                    AND name IS NOT NULL
                """, (table_name,))
                indexes = cursor.fetchall()
                
                if indexes:
                    print("\nIndexes:")
                    index_data = []
                    for idx in indexes:
                        index_data.append({
                            'Name': idx[0],
                            'Definition': idx[1]
                        })
                    print(tabulate(
                        index_data,
                        headers='keys',
                        tablefmt='grid'
                    ))
                print("\n" + "="*50)

    except sqlite3.Error as e:
        print(f"Error accessing database: {e}")
        return False
    except Exception as e:
        print(f"Unexpected error: {e}")
        return False
    return True

def main():
    parser = argparse.ArgumentParser(description='Contest Database Viewer')
    parser.add_argument('--db', default='contest_data.db',
                      help='Database file path (default: contest_data.db)')
    parser.add_argument('-d', '--debug', action='store_true',
                      help='Enable debug mode')
    parser.add_argument('-s', '--sort', choices=['t', 'c', 'n', 's', 'q', 'u', 'e', 'p'],
                      default='t',
                      help='''Sort by: 
                      t=timestamp (default), 
                      c=callsign, 
                      n=contest name, 
                      s=score, 
                      q=QSOs, 
                      u=club, 
                      e=section, 
                      p=power''')
    parser.add_argument('-o', '--order', choices=['a', 'd'],
                      default='d', help='Sort order: a=ascending, d=descending (default)')
    parser.add_argument('-l', '--limit', type=int,
                      help='Limit number of records displayed')
    parser.add_argument('-b', '--bands', action='store_true',
                      help='Show band breakdown')
    parser.add_argument('-c', '--call',
                      help='Show data for specific callsign')
    parser.add_argument('-a', '--all', action='store_true',
                      help='Show full content of all fields')
    parser.add_argument('-t', '--latest', action='store_true',
                      help='Show only latest record for each callsign')
    parser.add_argument('-n', '--contest',
                      help='Show data for specific contest')
    parser.add_argument('--list-contests', action='store_true',
                      help='List all available contests')
    parser.add_argument('--stats', action='store_true',
                      help='Show database statistics')
    parser.add_argument('--qth', action='store_true',
                      help='Show QTH information for stations')
    parser.add_argument('--qth-stats', action='store_true',
                      help='Show QTH statistics')
    parser.add_argument('--structure', action='store_true',
                      help='Show database structure')
    parser.add_argument('--categories', action='store_true',
                      help='Show operating category statistics (power, assisted, transmitter, ops, bands, mode)')

    args = parser.parse_args()

    if args.categories:
        show_operating_categories(args.db, args.contest)
        return

    args = parser.parse_args()

    if args.categories:
        show_operating_categories(args.db, args.contest)
        return

    if args.structure:
        show_database_structure(args.db)
        return

    viewer = ContestDatabaseViewer(args.db, args.debug)

    if args.list_contests:
        contests = viewer.get_available_contests()
        print("\nAvailable contests:")
        for contest in contests:
            print(contest)
        return

    if args.stats:
        stats = viewer.get_contest_stats()
        viewer.display_stats(stats)
        return

    if args.qth_stats:
        stats = viewer.get_qth_statistics(args.contest)
        format_qth_statistics(stats)
        return
        
    if args.qth:
        data = viewer.get_qth_details(args.call, args.contest)
        format_qth_details(data)
        return

    if args.bands or args.call:
        data = viewer.get_band_breakdown(args.call, args.contest)
        viewer.display_band_breakdown(data)
    else:
        sort_order = 'DESC' if args.order == 'd' else 'ASC'
        data = viewer.get_contest_scores(args.sort, sort_order, args.limit, args.latest, args.contest)
        viewer.display_scores(data, args.all)

if __name__ == "__main__":
    main()

===== web_interface.py =====
#!/usr/bin/env python3
from flask import Flask, render_template, request, redirect, send_from_directory, jsonify, make_response
import sqlite3
import os
import logging
import sys
import traceback
import sql_queries
from score_reporter import ScoreReporter
from datetime import datetime

# Define Config class first
class Config:
    DB_PATH = '/opt/livescore/contest_data.db'
    OUTPUT_DIR = '/opt/livescore/reports'

# Set up detailed logging
logging.basicConfig(
    level=logging.ERROR,
    format='%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.FileHandler('/opt/livescore/logs/debug.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Log startup
logger.info("Starting web interface application")

try:
    # Create Flask app
    app = Flask(__name__)
    logger.info("Flask app created successfully")

except Exception as e:
    logger.error(f"Failed to create Flask app")
    logger.error(traceback.format_exc())
    raise

class Config:
    DB_PATH = '/opt/livescore/contest_data.db'
    OUTPUT_DIR = '/opt/livescore/reports'

def get_db():
    """Database connection with logging"""
    logger.debug("Attempting database connection")
    try:
        conn = sqlite3.connect(Config.DB_PATH)
        logger.debug("Database connection successful")
        return conn
    except Exception as e:
        logger.error(f"Database connection failed: {str(e)}")
        logger.error(traceback.format_exc())
        raise



@app.route('/livescore-pilot', methods=['GET', 'POST'])
def index():
    logger.debug(f"Request received: {request.method}")
    
    try:
        with get_db() as db:
            cursor = db.cursor()
            
            # Get contests with station counts
            cursor.execute(sql_queries.GET_CONTESTS)
            contests = [{"name": row[0], "count": row[1]} for row in cursor.fetchall()]
            
            # Get contest and callsign from form or query parameters
            selected_contest = request.form.get('contest') or request.args.get('contest')
            selected_callsign = request.form.get('callsign') or request.args.get('callsign')
            
            callsigns = []
            
            if selected_contest:
                # Fetch unique callsigns with their latest QSO count for the selected contest
                cursor.execute(sql_queries.GET_CALLSIGNS, (selected_contest, selected_contest))
                callsigns = [{"name": row[0], "qso_count": row[1]} for row in cursor.fetchall()]
                
        return render_template('select_form.html', 
                             contests=contests,
                             selected_contest=selected_contest,
                             selected_callsign=selected_callsign,
                             callsigns=callsigns)
    
    except Exception as e:
        logger.error("Exception in index route:")
        logger.error(traceback.format_exc())
        return render_template('error.html', error=f"Error: {str(e)}")

@app.route('/reports/live.html')
def live_report():
    try:
        # Get parameters from URL
        callsign = request.args.get('callsign')
        contest = request.args.get('contest')
        filter_type = request.args.get('filter_type', 'none')
        filter_value = request.args.get('filter_value', 'none')

        if not (callsign and contest):
            return render_template('error.html', error="Missing required parameters")

        logger.info(f"Generating report for: contest={contest}, callsign={callsign}, "
                   f"filter_type={filter_type}, filter_value={filter_value}")

        # Create reporter instance
        reporter = ScoreReporter(Config.DB_PATH)

        # Verify contest and callsign exist in database
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute(sql_queries.VERIFY_STATION, (contest, callsign))
            if cursor.fetchone()[0] == 0:
                return render_template('error.html', 
                    error=f"No data found for {callsign} in {contest}")

        # Get station data with filters
        stations = reporter.get_station_details(callsign, contest, filter_type, filter_value)

        if stations:
            # Generate HTML content directly
            template_path = os.path.join(os.path.dirname(__file__), 'templates', 'score_template.html')
            with open(template_path, 'r') as f:
                template = f.read()

            html_content = reporter.generate_html_content(template, callsign, contest, stations)
            
            # Return response with appropriate headers
            response = make_response(html_content)
            response.headers['Content-Type'] = 'text/html; charset=utf-8'
            response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
            response.headers['Pragma'] = 'no-cache'
            response.headers['Expires'] = '0'
            
            logger.info(f"Successfully generated report for {callsign} in {contest}")
            return response
        else:
            logger.error(f"No station data found for {callsign} in {contest}")
            return render_template('error.html', error="No data found for the selected criteria")

    except Exception as e:
        logger.error("Exception in live_report:")
        logger.error(traceback.format_exc())
        return render_template('error.html', error=f"Error: {str(e)}")

@app.errorhandler(404)
def not_found_error(error):
    logger.error(f"404 error: {error}")
    return render_template('error.html', error="Page not found"), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"500 error: {error}")
    logger.error(traceback.format_exc())
    return render_template('error.html', error="Internal server error"), 500

@app.route('/livescore-pilot/api/contests')
def get_contests():
    try:
        with get_db() as db:
            cursor = db.cursor()
            cursor.execute(sql_queries.API_GET_CONTESTS)
            contests = [{"name": row[0], "count": row[1]} for row in cursor.fetchall()]
            return jsonify(contests)
    except Exception as e:
        logger.error(f"Error fetching contests: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/livescore-pilot/api/callsigns')
def get_callsigns():
    contest = request.args.get('contest')
    if not contest:
        return jsonify({"error": "Contest parameter required"}), 400

    try:
        with get_db() as db:
            cursor = db.cursor()
            cursor.execute(sql_queries.API_GET_CALLSIGNS, (contest,))
            callsigns = [{"name": row[0]} for row in cursor.fetchall()]
            return jsonify(callsigns)
    except Exception as e:
        logger.error(f"Error fetching callsigns: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/livescore-pilot/api/filters')
def get_filters():
    contest = request.args.get('contest')
    callsign = request.args.get('callsign')
    
    if not contest or not callsign:
        return jsonify({"error": "Contest and callsign parameters required"}), 400

    try:
        with get_db() as db:
            cursor = db.cursor()
            cursor.execute(sql_queries.GET_FILTERS, (contest, callsign))
            
            row = cursor.fetchone()
            if not row:
                return jsonify([])

            filters = []
            filter_map = {
                'DXCC': row[0],
                'CQ Zone': row[1],
                'IARU Zone': row[2],
                'ARRL Section': row[3],
                'State/Province': row[4],
                'Continent': row[5]
            }

            for filter_type, value in filter_map.items():
                if value:  # Only include non-empty values
                    filters.append({
                        "type": filter_type,
                        "value": value
                    })

            return jsonify(filters)
    except Exception as e:
        logger.error(f"Error fetching filters: {str(e)}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    logger.info("Starting development server")
    app.run(host='127.0.0.1', port=8089)
else:
    # When running under gunicorn
    logger.info("Starting under gunicorn")

